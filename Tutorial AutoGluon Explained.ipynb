{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/taimour/s4e9-autogluon-explained-regression?scriptVersionId=196528449\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"24c474aa","metadata":{"papermill":{"duration":0.006364,"end_time":"2024-09-13T16:25:16.006355","exception":false,"start_time":"2024-09-13T16:25:15.999991","status":"completed"},"tags":[]},"source":["# Tutorial - AutoGluon Explained\n","![](https://auto.gluon.ai/stable/_static/autogluon.png)"]},{"cell_type":"markdown","id":"3475a2e8","metadata":{"papermill":{"duration":0.005329,"end_time":"2024-09-13T16:25:16.017489","exception":false,"start_time":"2024-09-13T16:25:16.01216","status":"completed"},"tags":[]},"source":["# Installation\n","\n","To keep notebook clean and avoid alot of installation text in notebook, lets use subprocess"]},{"cell_type":"code","execution_count":1,"id":"d3e8cb0d","metadata":{"execution":{"iopub.execute_input":"2024-09-13T16:25:16.030782Z","iopub.status.busy":"2024-09-13T16:25:16.029997Z","iopub.status.idle":"2024-09-13T16:26:23.55019Z","shell.execute_reply":"2024-09-13T16:26:23.549194Z"},"papermill":{"duration":67.535569,"end_time":"2024-09-13T16:26:23.558645","exception":false,"start_time":"2024-09-13T16:25:16.023076","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["CompletedProcess(args=['pip', 'install', '-U', 'ipywidgets'], returncode=0, stdout=b'Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.1)\\nCollecting ipywidgets\\n  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\\nRequirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\\nRequirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.21.0)\\nRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\\nCollecting widgetsnbextension~=4.0.12 (from ipywidgets)\\n  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\\nCollecting jupyterlab-widgets~=3.0.12 (from ipywidgets)\\n  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\\nRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.47)\\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.0)\\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\\nDownloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\\n\\x1b[?25l   \\x1b[90m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m \\x1b[32m0.0/139.8 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m\\r\\x1b[2K   \\x1b[91m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m\\x1b[91m\\xe2\\x95\\xb8\\x1b[0m\\x1b[90m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m \\x1b[32m71.7/139.8 kB\\x1b[0m \\x1b[31m2.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m\\r\\x1b[2K   \\x1b[90m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m \\x1b[32m139.8/139.8 kB\\x1b[0m \\x1b[31m2.4 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m\\n\\x1b[?25hDownloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\\n\\x1b[?25l   \\x1b[90m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m \\x1b[32m0.0/214.4 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m\\r\\x1b[2K   \\x1b[90m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m \\x1b[32m214.4/214.4 kB\\x1b[0m \\x1b[31m7.6 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m\\n\\x1b[?25hDownloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\\n\\x1b[?25l   \\x1b[90m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m \\x1b[32m0.0/2.3 MB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m\\r\\x1b[2K   \\x1b[91m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m\\x1b[91m\\xe2\\x95\\xb8\\x1b[0m \\x1b[32m2.3/2.3 MB\\x1b[0m \\x1b[31m75.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m\\r\\x1b[2K   \\x1b[90m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m \\x1b[32m2.3/2.3 MB\\x1b[0m \\x1b[31m42.1 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m\\n\\x1b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\\n  Attempting uninstall: widgetsnbextension\\n    Found existing installation: widgetsnbextension 3.6.8\\n    Uninstalling widgetsnbextension-3.6.8:\\n      Successfully uninstalled widgetsnbextension-3.6.8\\n  Attempting uninstall: jupyterlab-widgets\\n    Found existing installation: jupyterlab_widgets 3.0.11\\n    Uninstalling jupyterlab_widgets-3.0.11:\\n      Successfully uninstalled jupyterlab_widgets-3.0.11\\n  Attempting uninstall: ipywidgets\\n    Found existing installation: ipywidgets 7.7.1\\n    Uninstalling ipywidgets-7.7.1:\\n      Successfully uninstalled ipywidgets-7.7.1\\nSuccessfully installed ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\\n', stderr=b\"\\x1b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\\nbigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\\nbigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\\nbigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.2 which is incompatible.\\ndataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.8.2 which is incompatible.\\x1b[0m\\x1b[31m\\n\\x1b[0m\")"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import subprocess\n","\n","subprocess.run([\"pip\", \"install\", \"ray==2.10.0\"], capture_output=True)\n","subprocess.run([\"pip\", \"install\", \"autogluon.tabular\"], capture_output=True)\n","subprocess.run([\"pip\", \"install\", \"-U\", \"ipywidgets\"], capture_output=True)"]},{"cell_type":"markdown","id":"9a5eb957","metadata":{"papermill":{"duration":0.00568,"end_time":"2024-09-13T16:26:23.570191","exception":false,"start_time":"2024-09-13T16:26:23.564511","status":"completed"},"tags":[]},"source":["# Import"]},{"cell_type":"code","execution_count":2,"id":"61bed393","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-13T16:26:23.583112Z","iopub.status.busy":"2024-09-13T16:26:23.582752Z","iopub.status.idle":"2024-09-13T16:26:25.956898Z","shell.execute_reply":"2024-09-13T16:26:25.955913Z"},"papermill":{"duration":2.383384,"end_time":"2024-09-13T16:26:25.959397","exception":false,"start_time":"2024-09-13T16:26:23.576013","status":"completed"},"tags":[]},"outputs":[],"source":["import pandas as pd\n","from autogluon.tabular import TabularDataset, TabularPredictor"]},{"cell_type":"markdown","id":"29f70adc","metadata":{"papermill":{"duration":0.005792,"end_time":"2024-09-13T16:26:25.971394","exception":false,"start_time":"2024-09-13T16:26:25.965602","status":"completed"},"tags":[]},"source":["# Read Data"]},{"cell_type":"code","execution_count":3,"id":"a460df70","metadata":{"execution":{"iopub.execute_input":"2024-09-13T16:26:25.98446Z","iopub.status.busy":"2024-09-13T16:26:25.983962Z","iopub.status.idle":"2024-09-13T16:26:27.371598Z","shell.execute_reply":"2024-09-13T16:26:27.370778Z"},"papermill":{"duration":1.396779,"end_time":"2024-09-13T16:26:27.37399","exception":false,"start_time":"2024-09-13T16:26:25.977211","status":"completed"},"tags":[]},"outputs":[],"source":["train_data = pd.read_csv('/kaggle/input/playground-series-s4e9/train.csv').drop('id', axis=1)\n","test_data = pd.read_csv('/kaggle/input/playground-series-s4e9/test.csv').drop('id', axis=1)\n","submission = pd.read_csv('/kaggle/input/playground-series-s4e9/sample_submission.csv')"]},{"cell_type":"markdown","id":"8def54a0","metadata":{"papermill":{"duration":0.005772,"end_time":"2024-09-13T16:26:27.386096","exception":false,"start_time":"2024-09-13T16:26:27.380324","status":"completed"},"tags":[]},"source":["# View Training and Test data"]},{"cell_type":"code","execution_count":4,"id":"4bc8469d","metadata":{"execution":{"iopub.execute_input":"2024-09-13T16:26:27.398965Z","iopub.status.busy":"2024-09-13T16:26:27.398606Z","iopub.status.idle":"2024-09-13T16:26:27.415638Z","shell.execute_reply":"2024-09-13T16:26:27.4148Z"},"papermill":{"duration":0.025626,"end_time":"2024-09-13T16:26:27.417514","exception":false,"start_time":"2024-09-13T16:26:27.391888","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>brand</th>\n","      <th>model</th>\n","      <th>model_year</th>\n","      <th>milage</th>\n","      <th>fuel_type</th>\n","      <th>engine</th>\n","      <th>transmission</th>\n","      <th>ext_col</th>\n","      <th>int_col</th>\n","      <th>accident</th>\n","      <th>clean_title</th>\n","      <th>price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>MINI</td>\n","      <td>Cooper S Base</td>\n","      <td>2007</td>\n","      <td>213000</td>\n","      <td>Gasoline</td>\n","      <td>172.0HP 1.6L 4 Cylinder Engine Gasoline Fuel</td>\n","      <td>A/T</td>\n","      <td>Yellow</td>\n","      <td>Gray</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","      <td>4200</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Lincoln</td>\n","      <td>LS V8</td>\n","      <td>2002</td>\n","      <td>143250</td>\n","      <td>Gasoline</td>\n","      <td>252.0HP 3.9L 8 Cylinder Engine Gasoline Fuel</td>\n","      <td>A/T</td>\n","      <td>Silver</td>\n","      <td>Beige</td>\n","      <td>At least 1 accident or damage reported</td>\n","      <td>Yes</td>\n","      <td>4999</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Chevrolet</td>\n","      <td>Silverado 2500 LT</td>\n","      <td>2002</td>\n","      <td>136731</td>\n","      <td>E85 Flex Fuel</td>\n","      <td>320.0HP 5.3L 8 Cylinder Engine Flex Fuel Capab...</td>\n","      <td>A/T</td>\n","      <td>Blue</td>\n","      <td>Gray</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","      <td>13900</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Genesis</td>\n","      <td>G90 5.0 Ultimate</td>\n","      <td>2017</td>\n","      <td>19500</td>\n","      <td>Gasoline</td>\n","      <td>420.0HP 5.0L 8 Cylinder Engine Gasoline Fuel</td>\n","      <td>Transmission w/Dual Shift Mode</td>\n","      <td>Black</td>\n","      <td>Black</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","      <td>45000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Mercedes-Benz</td>\n","      <td>Metris Base</td>\n","      <td>2021</td>\n","      <td>7388</td>\n","      <td>Gasoline</td>\n","      <td>208.0HP 2.0L 4 Cylinder Engine Gasoline Fuel</td>\n","      <td>7-Speed A/T</td>\n","      <td>Black</td>\n","      <td>Beige</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","      <td>97500</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           brand              model  model_year  milage      fuel_type  \\\n","0           MINI      Cooper S Base        2007  213000       Gasoline   \n","1        Lincoln              LS V8        2002  143250       Gasoline   \n","2      Chevrolet  Silverado 2500 LT        2002  136731  E85 Flex Fuel   \n","3        Genesis   G90 5.0 Ultimate        2017   19500       Gasoline   \n","4  Mercedes-Benz        Metris Base        2021    7388       Gasoline   \n","\n","                                              engine  \\\n","0       172.0HP 1.6L 4 Cylinder Engine Gasoline Fuel   \n","1       252.0HP 3.9L 8 Cylinder Engine Gasoline Fuel   \n","2  320.0HP 5.3L 8 Cylinder Engine Flex Fuel Capab...   \n","3       420.0HP 5.0L 8 Cylinder Engine Gasoline Fuel   \n","4       208.0HP 2.0L 4 Cylinder Engine Gasoline Fuel   \n","\n","                     transmission ext_col int_col  \\\n","0                             A/T  Yellow    Gray   \n","1                             A/T  Silver   Beige   \n","2                             A/T    Blue    Gray   \n","3  Transmission w/Dual Shift Mode   Black   Black   \n","4                     7-Speed A/T   Black   Beige   \n","\n","                                 accident clean_title  price  \n","0                           None reported         Yes   4200  \n","1  At least 1 accident or damage reported         Yes   4999  \n","2                           None reported         Yes  13900  \n","3                           None reported         Yes  45000  \n","4                           None reported         Yes  97500  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["train_data.head()"]},{"cell_type":"code","execution_count":5,"id":"2b976566","metadata":{"execution":{"iopub.execute_input":"2024-09-13T16:26:27.430778Z","iopub.status.busy":"2024-09-13T16:26:27.430486Z","iopub.status.idle":"2024-09-13T16:26:27.443533Z","shell.execute_reply":"2024-09-13T16:26:27.442675Z"},"papermill":{"duration":0.021768,"end_time":"2024-09-13T16:26:27.445398","exception":false,"start_time":"2024-09-13T16:26:27.42363","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>brand</th>\n","      <th>model</th>\n","      <th>model_year</th>\n","      <th>milage</th>\n","      <th>fuel_type</th>\n","      <th>engine</th>\n","      <th>transmission</th>\n","      <th>ext_col</th>\n","      <th>int_col</th>\n","      <th>accident</th>\n","      <th>clean_title</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Land</td>\n","      <td>Rover LR2 Base</td>\n","      <td>2015</td>\n","      <td>98000</td>\n","      <td>Gasoline</td>\n","      <td>240.0HP 2.0L 4 Cylinder Engine Gasoline Fuel</td>\n","      <td>6-Speed A/T</td>\n","      <td>White</td>\n","      <td>Beige</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Land</td>\n","      <td>Rover Defender SE</td>\n","      <td>2020</td>\n","      <td>9142</td>\n","      <td>Hybrid</td>\n","      <td>395.0HP 3.0L Straight 6 Cylinder Engine Gasoli...</td>\n","      <td>8-Speed A/T</td>\n","      <td>Silver</td>\n","      <td>Black</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Ford</td>\n","      <td>Expedition Limited</td>\n","      <td>2022</td>\n","      <td>28121</td>\n","      <td>Gasoline</td>\n","      <td>3.5L V6 24V PDI DOHC Twin Turbo</td>\n","      <td>10-Speed Automatic</td>\n","      <td>White</td>\n","      <td>Ebony</td>\n","      <td>None reported</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Audi</td>\n","      <td>A6 2.0T Sport</td>\n","      <td>2016</td>\n","      <td>61258</td>\n","      <td>Gasoline</td>\n","      <td>2.0 Liter TFSI</td>\n","      <td>Automatic</td>\n","      <td>Silician Yellow</td>\n","      <td>Black</td>\n","      <td>None reported</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Audi</td>\n","      <td>A6 2.0T Premium Plus</td>\n","      <td>2018</td>\n","      <td>59000</td>\n","      <td>Gasoline</td>\n","      <td>252.0HP 2.0L 4 Cylinder Engine Gasoline Fuel</td>\n","      <td>A/T</td>\n","      <td>Gray</td>\n","      <td>Black</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  brand                 model  model_year  milage fuel_type  \\\n","0  Land        Rover LR2 Base        2015   98000  Gasoline   \n","1  Land     Rover Defender SE        2020    9142    Hybrid   \n","2  Ford    Expedition Limited        2022   28121  Gasoline   \n","3  Audi         A6 2.0T Sport        2016   61258  Gasoline   \n","4  Audi  A6 2.0T Premium Plus        2018   59000  Gasoline   \n","\n","                                              engine        transmission  \\\n","0       240.0HP 2.0L 4 Cylinder Engine Gasoline Fuel         6-Speed A/T   \n","1  395.0HP 3.0L Straight 6 Cylinder Engine Gasoli...         8-Speed A/T   \n","2                    3.5L V6 24V PDI DOHC Twin Turbo  10-Speed Automatic   \n","3                                     2.0 Liter TFSI           Automatic   \n","4       252.0HP 2.0L 4 Cylinder Engine Gasoline Fuel                 A/T   \n","\n","           ext_col int_col       accident clean_title  \n","0            White   Beige  None reported         Yes  \n","1           Silver   Black  None reported         Yes  \n","2            White   Ebony  None reported         NaN  \n","3  Silician Yellow   Black  None reported         NaN  \n","4             Gray   Black  None reported         Yes  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["test_data.head()"]},{"cell_type":"markdown","id":"c46266ff","metadata":{"papermill":{"duration":0.006204,"end_time":"2024-09-13T16:26:27.458016","exception":false,"start_time":"2024-09-13T16:26:27.451812","status":"completed"},"tags":[]},"source":["# AutoGluon Introduction\n","\n","AutoGluon is an open-source AutoML framework developed by Amazon that simplifies the process of building machine learning models for various tasks, including tabular data prediction, image classification, text analysis, and more. It automates the entire machine learning pipeline, from data preprocessing to model selection and hyperparameter tuning, making it accessible for users with minimal coding and machine learning expertise. AutoGluon supports both classification and regression problems and leverages powerful ensemble techniques to deliver high-quality models. It also allows users to specify resource constraints, like time limits and hardware availability (GPUs/CPUs), to optimize model training efficiency."]},{"cell_type":"markdown","id":"a164a795","metadata":{"papermill":{"duration":0.006277,"end_time":"2024-09-13T16:26:27.470631","exception":false,"start_time":"2024-09-13T16:26:27.464354","status":"completed"},"tags":[]},"source":["# AutoGluon Code with Explanation"]},{"cell_type":"code","execution_count":6,"id":"bacb852a","metadata":{"execution":{"iopub.execute_input":"2024-09-13T16:26:27.484505Z","iopub.status.busy":"2024-09-13T16:26:27.48422Z","iopub.status.idle":"2024-09-13T19:26:20.112943Z","shell.execute_reply":"2024-09-13T19:26:20.111869Z"},"papermill":{"duration":10792.639216,"end_time":"2024-09-13T19:26:20.116205","exception":false,"start_time":"2024-09-13T16:26:27.476989","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["No path specified. Models will be saved in: \"AutogluonModels/ag-20240913_162627\"\n","2024-09-13 16:26:30,796\tINFO worker.py:1752 -- Started a local Ray instance.\n","\u001b[36m(_ray_fit pid=452)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=452)\u001b[0m [LightGBM] [Fatal] bin size 1669 cannot run on GPU\n","\u001b[36m(_ray_fit pid=452)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=494)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=494)\u001b[0m [LightGBM] [Fatal] bin size 1665 cannot run on GPU\n","\u001b[36m(_ray_fit pid=494)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=536)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=536)\u001b[0m [LightGBM] [Fatal] bin size 1670 cannot run on GPU\n","\u001b[36m(_ray_fit pid=536)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=578)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=578)\u001b[0m [LightGBM] [Fatal] bin size 1666 cannot run on GPU\n","\u001b[36m(_ray_fit pid=578)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=620)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=620)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=620)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=662)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=662)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=662)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=704)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=704)\u001b[0m [LightGBM] [Fatal] bin size 1664 cannot run on GPU\n","\u001b[36m(_ray_fit pid=704)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=746)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=746)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n","\u001b[36m(_ray_fit pid=746)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=878)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=878)\u001b[0m [LightGBM] [Fatal] bin size 1669 cannot run on GPU\n","\u001b[36m(_ray_fit pid=878)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=920)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=920)\u001b[0m [LightGBM] [Fatal] bin size 1665 cannot run on GPU\n","\u001b[36m(_ray_fit pid=920)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=962)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=962)\u001b[0m [LightGBM] [Fatal] bin size 1670 cannot run on GPU\n","\u001b[36m(_ray_fit pid=962)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=1004)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1004)\u001b[0m [LightGBM] [Fatal] bin size 1666 cannot run on GPU\n","\u001b[36m(_ray_fit pid=1004)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=1046)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1046)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=1046)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=1088)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1088)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=1088)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=1130)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1130)\u001b[0m [LightGBM] [Fatal] bin size 1664 cannot run on GPU\n","\u001b[36m(_ray_fit pid=1130)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=1172)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1172)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n","\u001b[36m(_ray_fit pid=1172)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=1318)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1318)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=1391)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1391)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=1464)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1464)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=1538)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1538)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=1611)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1611)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=1684)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1684)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=1757)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1757)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=1830)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1830)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=2007)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2007)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=2059)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2059)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=2111)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2111)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=2163)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2163)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=2215)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2215)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=2267)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2267)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=2319)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2319)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=2371)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2371)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=2513)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:51:28] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=2513)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=2513)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:51:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=2513)\u001b[0m \n","\u001b[36m(_ray_fit pid=2513)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=2513)\u001b[0m \n","\u001b[36m(_ray_fit pid=2513)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=2513)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:51:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=2513)\u001b[0m \n","\u001b[36m(_ray_fit pid=2513)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=2513)\u001b[0m \n","\u001b[36m(_ray_fit pid=2513)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=2513)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:51:29] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=2513)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=2513)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=2513)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=2513)\u001b[0m \n","\u001b[36m(_ray_fit pid=2513)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=2513)\u001b[0m \n","\u001b[36m(_ray_fit pid=2513)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=2556)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:51:33] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=2556)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n","\u001b[36m(_ray_fit pid=2556)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:51:33] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=2556)\u001b[0m \u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2556)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=2556)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:51:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=2556)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=2556)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:51:34] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=2556)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=2556)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=2556)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=2556)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=2599)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:51:38] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=2599)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:51:39] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=2599)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=2599)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=2599)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=2599)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=2599)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2599)\u001b[0m \u001b[32m [repeated 10x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2643)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:51:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2643)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2643)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:51:43] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=2686)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:51:48] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=2643)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:51:44] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=2643)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=2643)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=2643)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=2643)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=2686)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2686)\u001b[0m \u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2686)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:51:49] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=2686)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=2686)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=2686)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=2686)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=2686)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:51:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2686)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2729)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:51:53] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=2729)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2729)\u001b[0m \u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2773)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:51:58] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=2729)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:51:53] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=2729)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=2729)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=2729)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=2729)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=2773)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:51:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2773)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2773)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:51:58] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=2773)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=2773)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=2773)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=2773)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=2773)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2773)\u001b[0m \u001b[32m [repeated 10x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2817)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:52:02] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=2817)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:52:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2817)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2950)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 10)\n","\u001b[36m(_ray_fit pid=2950)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2950)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=2817)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [16:52:03] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=2817)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=2817)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=2817)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=2817)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=2817)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2817)\u001b[0m \u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2996)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 10)\n","\u001b[36m(_ray_fit pid=2996)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2996)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=3042)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 10)\n","\u001b[36m(_ray_fit pid=3042)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=3042)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=3088)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 10)\n","\u001b[36m(_ray_fit pid=3088)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=3088)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=3134)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 10)\n","\u001b[36m(_ray_fit pid=3134)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=3134)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=3180)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 10)\n","\u001b[36m(_ray_fit pid=3180)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=3180)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=3226)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 10)\n","\u001b[36m(_ray_fit pid=3226)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=3226)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=3272)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 10)\n","\u001b[36m(_ray_fit pid=3272)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=3272)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=3408)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3408)\u001b[0m [LightGBM] [Fatal] bin size 1669 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3408)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3408)\u001b[0m \tRan out of time, early stopping on iteration 97. Best iteration is:\n","\u001b[36m(_ray_fit pid=3408)\u001b[0m \t[61]\tvalid_set's rmse: 82621.6\n","\u001b[36m(_ray_fit pid=3450)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3450)\u001b[0m [LightGBM] [Fatal] bin size 1665 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3450)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3450)\u001b[0m \tRan out of time, early stopping on iteration 71. Best iteration is:\n","\u001b[36m(_ray_fit pid=3450)\u001b[0m \t[60]\tvalid_set's rmse: 84131.4\n","\u001b[36m(_ray_fit pid=3492)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3492)\u001b[0m [LightGBM] [Fatal] bin size 1670 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3492)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3534)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3534)\u001b[0m [LightGBM] [Fatal] bin size 1666 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3534)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3576)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3576)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3576)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3618)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3618)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3618)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3618)\u001b[0m \tRan out of time, early stopping on iteration 105. Best iteration is:\n","\u001b[36m(_ray_fit pid=3618)\u001b[0m \t[72]\tvalid_set's rmse: 70483.5\n","\u001b[36m(_ray_fit pid=3660)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3660)\u001b[0m [LightGBM] [Fatal] bin size 1664 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3660)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3702)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3702)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3702)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3840)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3840)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3840)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3882)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3882)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3882)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3924)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3924)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3924)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3966)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3966)\u001b[0m [LightGBM] [Fatal] bin size 1666 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3966)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=4008)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4008)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=4008)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=4050)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4050)\u001b[0m [LightGBM] [Fatal] bin size 1670 cannot run on GPU\n","\u001b[36m(_ray_fit pid=4050)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=4092)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4092)\u001b[0m [LightGBM] [Fatal] bin size 1665 cannot run on GPU\n","\u001b[36m(_ray_fit pid=4092)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=4134)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4134)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=4134)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=4272)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4272)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=4272)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=4314)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4314)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n","\u001b[36m(_ray_fit pid=4314)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=4356)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4356)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n","\u001b[36m(_ray_fit pid=4356)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=4398)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4398)\u001b[0m [LightGBM] [Fatal] bin size 1666 cannot run on GPU\n","\u001b[36m(_ray_fit pid=4398)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=4440)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4440)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=4440)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=4482)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4482)\u001b[0m [LightGBM] [Fatal] bin size 1670 cannot run on GPU\n","\u001b[36m(_ray_fit pid=4482)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=4524)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4524)\u001b[0m [LightGBM] [Fatal] bin size 1665 cannot run on GPU\n","\u001b[36m(_ray_fit pid=4524)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=4566)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4566)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=4566)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=4718)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4718)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_dystack pid=187)\u001b[0m Failed to unpickle serialized exception\n","\u001b[36m(_dystack pid=187)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=187)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/exceptions.py\", line 46, in from_ray_exception\n","\u001b[36m(_dystack pid=187)\u001b[0m     return pickle.loads(ray_exception.serialized_exception)\n","\u001b[36m(_dystack pid=187)\u001b[0m ModuleNotFoundError: No module named '_catboost'\n","\u001b[36m(_dystack pid=187)\u001b[0m \n","\u001b[36m(_dystack pid=187)\u001b[0m The above exception was the direct cause of the following exception:\n","\u001b[36m(_dystack pid=187)\u001b[0m \n","\u001b[36m(_dystack pid=187)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=187)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/serialization.py\", line 404, in deserialize_objects\n","\u001b[36m(_dystack pid=187)\u001b[0m     obj = self._deserialize_object(data, metadata, object_ref)\n","\u001b[36m(_dystack pid=187)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/serialization.py\", line 293, in _deserialize_object\n","\u001b[36m(_dystack pid=187)\u001b[0m     return RayError.from_bytes(obj)\n","\u001b[36m(_dystack pid=187)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/exceptions.py\", line 40, in from_bytes\n","\u001b[36m(_dystack pid=187)\u001b[0m     return RayError.from_ray_exception(ray_exception)\n","\u001b[36m(_dystack pid=187)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/exceptions.py\", line 49, in from_ray_exception\n","\u001b[36m(_dystack pid=187)\u001b[0m     raise RuntimeError(msg) from e\n","\u001b[36m(_dystack pid=187)\u001b[0m RuntimeError: Failed to unpickle serialized exception\n","\u001b[36m(_dystack pid=187)\u001b[0m \tWarning: Exception caused CatBoost_BAG_L2 to fail during training... Skipping this model.\n","\u001b[36m(_dystack pid=187)\u001b[0m \t\tSystem error: Failed to unpickle serialized exception\n","\u001b[36m(_dystack pid=187)\u001b[0m traceback: Traceback (most recent call last):\n","\u001b[36m(_dystack pid=187)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/exceptions.py\", line 46, in from_ray_exception\n","\u001b[36m(_dystack pid=187)\u001b[0m     return pickle.loads(ray_exception.serialized_exception)\n","\u001b[36m(_dystack pid=187)\u001b[0m ModuleNotFoundError: No module named '_catboost'\n","\u001b[36m(_dystack pid=187)\u001b[0m \n","\u001b[36m(_dystack pid=187)\u001b[0m The above exception was the direct cause of the following exception:\n","\u001b[36m(_dystack pid=187)\u001b[0m \n","\u001b[36m(_dystack pid=187)\u001b[0m Traceback (most recent call last):\n","\u001b[36m(_dystack pid=187)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/serialization.py\", line 404, in deserialize_objects\n","\u001b[36m(_dystack pid=187)\u001b[0m     obj = self._deserialize_object(data, metadata, object_ref)\n","\u001b[36m(_dystack pid=187)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/serialization.py\", line 293, in _deserialize_object\n","\u001b[36m(_dystack pid=187)\u001b[0m     return RayError.from_bytes(obj)\n","\u001b[36m(_dystack pid=187)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/exceptions.py\", line 40, in from_bytes\n","\u001b[36m(_dystack pid=187)\u001b[0m     return RayError.from_ray_exception(ray_exception)\n","\u001b[36m(_dystack pid=187)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/exceptions.py\", line 49, in from_ray_exception\n","\u001b[36m(_dystack pid=187)\u001b[0m     raise RuntimeError(msg) from e\n","\u001b[36m(_dystack pid=187)\u001b[0m RuntimeError: Failed to unpickle serialized exception\n","\u001b[36m(_dystack pid=187)\u001b[0m \n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n"]}],"source":["predictor = TabularPredictor(\n","    label='price',             # Target column that needs to be predicted (dependent variable)\n","    eval_metric='rmse',        # Evaluation metric (Root Mean Squared Error) used to judge the models performance\n","    problem_type='regression'  # Specifying this is a regression problem\n",").fit(\n","    train_data,                  # The training dataset containing features and the target (price)\n","    presets='best_quality',    # The preset configuration for optimal quality (though it may take more time)\n","    time_limit=3600*3,      # Time limit for training (3 hours = 3600 seconds/hour * 3 hours)\n","    verbosity=0,               # Level of logging information (0 is used to avoid alot of text in notebook)\n","    excluded_model_types=['KNN'], # Exclude K-Nearest Neighbors models from training\n","    ag_args_fit={\n","        'num_gpus': 1,          # Use 1 GPU if available for model training\n","        'num_cpus': 4           # Use 4 CPUs for model training\n","    }\n",")"]},{"cell_type":"markdown","id":"9a7860a9","metadata":{"papermill":{"duration":0.016852,"end_time":"2024-09-13T19:26:20.151381","exception":false,"start_time":"2024-09-13T19:26:20.134529","status":"completed"},"tags":[]},"source":["* **label='price':** The column name 'price' is the target (dependent variable) to be predicted.\n","* **eval_metric='rmse':** The Root Mean Squared Error (RMSE) is chosen as the evaluation metric, which is common for regression tasks.\n","* **problem_type='regression':** Specifies that the task is a regression task (i.e., predicting continuous values).\n","* **train_data:** This is the DataFrame containing the training data with both features and the target (price).\n","* **presets='best_quality':** This preset prioritizes accuracy over training speed. It will try many models and techniques to ensure the highest possible quality.\n","* **time_limit=3600*3:** Limits the model training process to a maximum of 3 hour.\n","* **verbosity=0:** Specifies the verbosity level for logging. Higher values will show more details about the training process. To avoid alot of text in notebook we will use 0.\n","* **excluded_model_types=['KNN']:** K-Nearest Neighbors (KNN) models are excluded from being considered during training.\n","* **ag_args_fit:** This argument allows you to pass configuration options to the fitting process:\n","* **num_gpus=1:** The model will utilize 1 GPU for training if available, speeding up the process for certain algorithms.\n","* **num_cpus=4:** The model will use 4 CPU cores during training."]},{"cell_type":"markdown","id":"19cc73bd","metadata":{"papermill":{"duration":0.017178,"end_time":"2024-09-13T19:26:20.185628","exception":false,"start_time":"2024-09-13T19:26:20.16845","status":"completed"},"tags":[]},"source":["# Why KNN models are excluded from training?\n","\n","**The exclusion of K-Nearest Neighbors (KNN) models from the training process in the given code is likely due to several reasons:**\n","\n","**Computational Cost:** KNN models can be computationally expensive for large datasets, especially when dealing with high-dimensional data. This is because they require calculating distances between each new data point and all training points, which can be time-consuming.\n","\n","**Sensitivity to Noise:** KNN models are sensitive to noise in the data. Outliers or noisy data points can significantly impact the predictions, leading to less accurate results.\n","\n","**Scalability Issues:** As the dataset size grows, KNN models can become increasingly difficult to scale. The computational complexity increases linearly with the number of training points, making it challenging to handle large datasets efficiently.\n","\n","**Interpretability:** KNN models are generally less interpretable compared to other machine learning algorithms. It can be difficult to understand how the model arrived at a particular prediction, making it harder to explain the model's behavior.\n","\n","\n","In summary, while KNN can be a simple and effective algorithm for certain problems, its drawbacks in terms of computational cost, sensitivity to noise, scalability, and interpretability make it less suitable for larger or more complex datasets. The decision to exclude KNN models from the training process in this specific case is likely based on these considerations and the desire to use more efficient and interpretable algorithms."]},{"cell_type":"code","execution_count":7,"id":"4846953b","metadata":{"execution":{"iopub.execute_input":"2024-09-13T19:26:20.221888Z","iopub.status.busy":"2024-09-13T19:26:20.220604Z","iopub.status.idle":"2024-09-13T19:26:20.951086Z","shell.execute_reply":"2024-09-13T19:26:20.950075Z"},"papermill":{"duration":0.750756,"end_time":"2024-09-13T19:26:20.953215","exception":false,"start_time":"2024-09-13T19:26:20.202459","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["*** Summary of fit() ***\n","Estimated performance of each model:\n","                          model     score_val              eval_metric  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n","0           WeightedEnsemble_L3 -72490.504440  root_mean_squared_error      74.438018  7142.474694                0.002777           0.559012            3       True         25\n","1               CatBoost_BAG_L2 -72519.993593  root_mean_squared_error      41.965800  5417.481269                0.529201          78.171062            2       True         20\n","2           WeightedEnsemble_L2 -72592.412648  root_mean_squared_error      36.106889  3857.897592                0.002920           0.418711            2       True         16\n","3             LightGBMXT_BAG_L2 -72674.286253  root_mean_squared_error      41.921645  5398.120039                0.485046          58.809832            2       True         17\n","4               CatBoost_BAG_L1 -72826.382752  root_mean_squared_error       0.963896   117.284948                0.963896         117.284948            1       True          4\n","5          CatBoost_r177_BAG_L1 -72832.213633  root_mean_squared_error       0.769926    90.295459                0.769926          90.295459            1       True         10\n","6        NeuralNetFastAI_BAG_L2 -72852.617889  root_mean_squared_error      44.777326  6040.602611                3.340727         701.292404            2       True         22\n","7           LightGBM_r96_BAG_L1 -72875.108129  root_mean_squared_error       2.106201    81.626262                2.106201          81.626262            1       True         15\n","8             LightGBMXT_BAG_L1 -72917.481425  root_mean_squared_error       0.650084    54.389211                0.650084          54.389211            1       True          1\n","9                XGBoost_BAG_L2 -72979.600664  root_mean_squared_error      42.679213  5385.194550                1.242614          45.884343            2       True         23\n","10        NeuralNetTorch_BAG_L2 -73007.606994  root_mean_squared_error      43.335339  5529.828161                1.898740         190.517954            2       True         24\n","11              LightGBM_BAG_L2 -73069.799767  root_mean_squared_error      41.804491  5396.750406                0.367892          57.440199            2       True         18\n","12         LightGBM_r131_BAG_L1 -73119.010616  root_mean_squared_error       1.319676    84.263240                1.319676          84.263240            1       True         12\n","13  NeuralNetFastAI_r191_BAG_L1 -73147.939163  root_mean_squared_error       3.361628   569.644032                3.361628         569.644032            1       True         13\n","14              LightGBM_BAG_L1 -73211.006130  root_mean_squared_error       0.426414    52.871367                0.426414          52.871367            1       True          2\n","15       NeuralNetFastAI_BAG_L1 -73221.848159  root_mean_squared_error       3.240030  1324.211187                3.240030        1324.211187            1       True          6\n","16        NeuralNetTorch_BAG_L1 -73426.844128  root_mean_squared_error       1.170087  1250.377174                1.170087        1250.377174            1       True          8\n","17    NeuralNetTorch_r79_BAG_L1 -73455.912780  root_mean_squared_error       1.286276  1011.879069                1.286276        1011.879069            1       True         11\n","18         LightGBMLarge_BAG_L1 -73620.198965  root_mean_squared_error       0.575871    60.936610                0.575871          60.936610            1       True          9\n","19               XGBoost_BAG_L1 -73649.378532  root_mean_squared_error       1.097240    39.307313                1.097240          39.307313            1       True          7\n","20         ExtraTreesMSE_BAG_L2 -73988.279802  root_mean_squared_error      55.543809  5659.970889               14.107210         320.660682            2       True         21\n","21       RandomForestMSE_BAG_L2 -74359.728198  root_mean_squared_error      57.415044  6493.756153               15.978445        1154.445946            2       True         19\n","22           CatBoost_r9_BAG_L1 -74833.791922  root_mean_squared_error       0.383230    49.583967                0.383230          49.583967            1       True         14\n","23         ExtraTreesMSE_BAG_L1 -77344.072883  root_mean_squared_error      11.942255   242.392245               11.942255         242.392245            1       True          5\n","24       RandomForestMSE_BAG_L1 -78153.007850  root_mean_squared_error      12.143784   310.248122               12.143784         310.248122            1       True          3\n","Number of models trained: 25\n","Types of models trained:\n","{'StackerEnsembleModel_TabularNeuralNetTorch', 'WeightedEnsembleModel', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_LGB'}\n","Bagging used: True  (with 8 folds)\n","Multi-layer stack-ensembling used: True  (with 3 levels)\n","Feature Metadata (Processed):\n","(raw dtype, special dtypes):\n","('category', [])                    :  7 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n","('category', ['text_as_category'])  :  1 | ['engine']\n","('int', [])                         :  2 | ['model_year', 'milage']\n","('int', ['binned', 'text_special']) : 11 | ['engine.char_count', 'engine.word_count', 'engine.capital_ratio', 'engine.lower_ratio', 'engine.digit_ratio', ...]\n","('int', ['bool'])                   :  1 | ['clean_title']\n","('int', ['text_ngram'])             : 65 | ['__nlp__.0hp', '__nlp__.0hp 0l', '__nlp__.0hp 0l cylinder', '__nlp__.0hp 0l straight', '__nlp__.0hp 0l v6', ...]\n","Plot summary of models saved to file: AutogluonModels/ag-20240913_162627SummaryOfModels.html\n","*** End of fit() summary ***\n"]}],"source":["results = predictor.fit_summary()"]},{"cell_type":"markdown","id":"969f5b6e","metadata":{"papermill":{"duration":0.017684,"end_time":"2024-09-13T19:26:20.988549","exception":false,"start_time":"2024-09-13T19:26:20.970865","status":"completed"},"tags":[]},"source":["* **fit_summary():** After training is complete, this method outputs a summary of the models trained, their performance, and additional statistics. The results object will contain information such as the leaderboard of model performance, training times, and which model was selected as the best for predictions."]},{"cell_type":"markdown","id":"d9df0f7f","metadata":{"papermill":{"duration":0.017058,"end_time":"2024-09-13T19:26:21.022884","exception":false,"start_time":"2024-09-13T19:26:21.005826","status":"completed"},"tags":[]},"source":["# Models Leaderboard"]},{"cell_type":"code","execution_count":8,"id":"cce137a8","metadata":{"execution":{"iopub.execute_input":"2024-09-13T19:26:21.061645Z","iopub.status.busy":"2024-09-13T19:26:21.061257Z","iopub.status.idle":"2024-09-13T19:26:21.091017Z","shell.execute_reply":"2024-09-13T19:26:21.090033Z"},"papermill":{"duration":0.050557,"end_time":"2024-09-13T19:26:21.093154","exception":false,"start_time":"2024-09-13T19:26:21.042597","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>score_val</th>\n","      <th>eval_metric</th>\n","      <th>pred_time_val</th>\n","      <th>fit_time</th>\n","      <th>pred_time_val_marginal</th>\n","      <th>fit_time_marginal</th>\n","      <th>stack_level</th>\n","      <th>can_infer</th>\n","      <th>fit_order</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>WeightedEnsemble_L3</td>\n","      <td>-72490.504440</td>\n","      <td>root_mean_squared_error</td>\n","      <td>74.438018</td>\n","      <td>7142.474694</td>\n","      <td>0.002777</td>\n","      <td>0.559012</td>\n","      <td>3</td>\n","      <td>True</td>\n","      <td>25</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CatBoost_BAG_L2</td>\n","      <td>-72519.993593</td>\n","      <td>root_mean_squared_error</td>\n","      <td>41.965800</td>\n","      <td>5417.481269</td>\n","      <td>0.529201</td>\n","      <td>78.171062</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>WeightedEnsemble_L2</td>\n","      <td>-72592.412648</td>\n","      <td>root_mean_squared_error</td>\n","      <td>36.106889</td>\n","      <td>3857.897592</td>\n","      <td>0.002920</td>\n","      <td>0.418711</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>LightGBMXT_BAG_L2</td>\n","      <td>-72674.286253</td>\n","      <td>root_mean_squared_error</td>\n","      <td>41.921645</td>\n","      <td>5398.120039</td>\n","      <td>0.485046</td>\n","      <td>58.809832</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>CatBoost_BAG_L1</td>\n","      <td>-72826.382752</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.963896</td>\n","      <td>117.284948</td>\n","      <td>0.963896</td>\n","      <td>117.284948</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>CatBoost_r177_BAG_L1</td>\n","      <td>-72832.213633</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.769926</td>\n","      <td>90.295459</td>\n","      <td>0.769926</td>\n","      <td>90.295459</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>NeuralNetFastAI_BAG_L2</td>\n","      <td>-72852.617889</td>\n","      <td>root_mean_squared_error</td>\n","      <td>44.777326</td>\n","      <td>6040.602611</td>\n","      <td>3.340727</td>\n","      <td>701.292404</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>LightGBM_r96_BAG_L1</td>\n","      <td>-72875.108129</td>\n","      <td>root_mean_squared_error</td>\n","      <td>2.106201</td>\n","      <td>81.626262</td>\n","      <td>2.106201</td>\n","      <td>81.626262</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>LightGBMXT_BAG_L1</td>\n","      <td>-72917.481425</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.650084</td>\n","      <td>54.389211</td>\n","      <td>0.650084</td>\n","      <td>54.389211</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>XGBoost_BAG_L2</td>\n","      <td>-72979.600664</td>\n","      <td>root_mean_squared_error</td>\n","      <td>42.679213</td>\n","      <td>5385.194550</td>\n","      <td>1.242614</td>\n","      <td>45.884343</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>NeuralNetTorch_BAG_L2</td>\n","      <td>-73007.606994</td>\n","      <td>root_mean_squared_error</td>\n","      <td>43.335339</td>\n","      <td>5529.828161</td>\n","      <td>1.898740</td>\n","      <td>190.517954</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>LightGBM_BAG_L2</td>\n","      <td>-73069.799767</td>\n","      <td>root_mean_squared_error</td>\n","      <td>41.804491</td>\n","      <td>5396.750406</td>\n","      <td>0.367892</td>\n","      <td>57.440199</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>LightGBM_r131_BAG_L1</td>\n","      <td>-73119.010616</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1.319676</td>\n","      <td>84.263240</td>\n","      <td>1.319676</td>\n","      <td>84.263240</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>NeuralNetFastAI_r191_BAG_L1</td>\n","      <td>-73147.939163</td>\n","      <td>root_mean_squared_error</td>\n","      <td>3.361628</td>\n","      <td>569.644032</td>\n","      <td>3.361628</td>\n","      <td>569.644032</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>LightGBM_BAG_L1</td>\n","      <td>-73211.006130</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.426414</td>\n","      <td>52.871367</td>\n","      <td>0.426414</td>\n","      <td>52.871367</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>NeuralNetFastAI_BAG_L1</td>\n","      <td>-73221.848159</td>\n","      <td>root_mean_squared_error</td>\n","      <td>3.240030</td>\n","      <td>1324.211187</td>\n","      <td>3.240030</td>\n","      <td>1324.211187</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>NeuralNetTorch_BAG_L1</td>\n","      <td>-73426.844128</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1.170087</td>\n","      <td>1250.377174</td>\n","      <td>1.170087</td>\n","      <td>1250.377174</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>NeuralNetTorch_r79_BAG_L1</td>\n","      <td>-73455.912780</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1.286276</td>\n","      <td>1011.879069</td>\n","      <td>1.286276</td>\n","      <td>1011.879069</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>LightGBMLarge_BAG_L1</td>\n","      <td>-73620.198965</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.575871</td>\n","      <td>60.936610</td>\n","      <td>0.575871</td>\n","      <td>60.936610</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>XGBoost_BAG_L1</td>\n","      <td>-73649.378532</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1.097240</td>\n","      <td>39.307313</td>\n","      <td>1.097240</td>\n","      <td>39.307313</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>ExtraTreesMSE_BAG_L2</td>\n","      <td>-73988.279802</td>\n","      <td>root_mean_squared_error</td>\n","      <td>55.543809</td>\n","      <td>5659.970889</td>\n","      <td>14.107210</td>\n","      <td>320.660682</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>RandomForestMSE_BAG_L2</td>\n","      <td>-74359.728198</td>\n","      <td>root_mean_squared_error</td>\n","      <td>57.415044</td>\n","      <td>6493.756153</td>\n","      <td>15.978445</td>\n","      <td>1154.445946</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>CatBoost_r9_BAG_L1</td>\n","      <td>-74833.791922</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.383230</td>\n","      <td>49.583967</td>\n","      <td>0.383230</td>\n","      <td>49.583967</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>ExtraTreesMSE_BAG_L1</td>\n","      <td>-77344.072883</td>\n","      <td>root_mean_squared_error</td>\n","      <td>11.942255</td>\n","      <td>242.392245</td>\n","      <td>11.942255</td>\n","      <td>242.392245</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>RandomForestMSE_BAG_L1</td>\n","      <td>-78153.007850</td>\n","      <td>root_mean_squared_error</td>\n","      <td>12.143784</td>\n","      <td>310.248122</td>\n","      <td>12.143784</td>\n","      <td>310.248122</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                          model     score_val              eval_metric  \\\n","0           WeightedEnsemble_L3 -72490.504440  root_mean_squared_error   \n","1               CatBoost_BAG_L2 -72519.993593  root_mean_squared_error   \n","2           WeightedEnsemble_L2 -72592.412648  root_mean_squared_error   \n","3             LightGBMXT_BAG_L2 -72674.286253  root_mean_squared_error   \n","4               CatBoost_BAG_L1 -72826.382752  root_mean_squared_error   \n","5          CatBoost_r177_BAG_L1 -72832.213633  root_mean_squared_error   \n","6        NeuralNetFastAI_BAG_L2 -72852.617889  root_mean_squared_error   \n","7           LightGBM_r96_BAG_L1 -72875.108129  root_mean_squared_error   \n","8             LightGBMXT_BAG_L1 -72917.481425  root_mean_squared_error   \n","9                XGBoost_BAG_L2 -72979.600664  root_mean_squared_error   \n","10        NeuralNetTorch_BAG_L2 -73007.606994  root_mean_squared_error   \n","11              LightGBM_BAG_L2 -73069.799767  root_mean_squared_error   \n","12         LightGBM_r131_BAG_L1 -73119.010616  root_mean_squared_error   \n","13  NeuralNetFastAI_r191_BAG_L1 -73147.939163  root_mean_squared_error   \n","14              LightGBM_BAG_L1 -73211.006130  root_mean_squared_error   \n","15       NeuralNetFastAI_BAG_L1 -73221.848159  root_mean_squared_error   \n","16        NeuralNetTorch_BAG_L1 -73426.844128  root_mean_squared_error   \n","17    NeuralNetTorch_r79_BAG_L1 -73455.912780  root_mean_squared_error   \n","18         LightGBMLarge_BAG_L1 -73620.198965  root_mean_squared_error   \n","19               XGBoost_BAG_L1 -73649.378532  root_mean_squared_error   \n","20         ExtraTreesMSE_BAG_L2 -73988.279802  root_mean_squared_error   \n","21       RandomForestMSE_BAG_L2 -74359.728198  root_mean_squared_error   \n","22           CatBoost_r9_BAG_L1 -74833.791922  root_mean_squared_error   \n","23         ExtraTreesMSE_BAG_L1 -77344.072883  root_mean_squared_error   \n","24       RandomForestMSE_BAG_L1 -78153.007850  root_mean_squared_error   \n","\n","    pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  \\\n","0       74.438018  7142.474694                0.002777           0.559012   \n","1       41.965800  5417.481269                0.529201          78.171062   \n","2       36.106889  3857.897592                0.002920           0.418711   \n","3       41.921645  5398.120039                0.485046          58.809832   \n","4        0.963896   117.284948                0.963896         117.284948   \n","5        0.769926    90.295459                0.769926          90.295459   \n","6       44.777326  6040.602611                3.340727         701.292404   \n","7        2.106201    81.626262                2.106201          81.626262   \n","8        0.650084    54.389211                0.650084          54.389211   \n","9       42.679213  5385.194550                1.242614          45.884343   \n","10      43.335339  5529.828161                1.898740         190.517954   \n","11      41.804491  5396.750406                0.367892          57.440199   \n","12       1.319676    84.263240                1.319676          84.263240   \n","13       3.361628   569.644032                3.361628         569.644032   \n","14       0.426414    52.871367                0.426414          52.871367   \n","15       3.240030  1324.211187                3.240030        1324.211187   \n","16       1.170087  1250.377174                1.170087        1250.377174   \n","17       1.286276  1011.879069                1.286276        1011.879069   \n","18       0.575871    60.936610                0.575871          60.936610   \n","19       1.097240    39.307313                1.097240          39.307313   \n","20      55.543809  5659.970889               14.107210         320.660682   \n","21      57.415044  6493.756153               15.978445        1154.445946   \n","22       0.383230    49.583967                0.383230          49.583967   \n","23      11.942255   242.392245               11.942255         242.392245   \n","24      12.143784   310.248122               12.143784         310.248122   \n","\n","    stack_level  can_infer  fit_order  \n","0             3       True         25  \n","1             2       True         20  \n","2             2       True         16  \n","3             2       True         17  \n","4             1       True          4  \n","5             1       True         10  \n","6             2       True         22  \n","7             1       True         15  \n","8             1       True          1  \n","9             2       True         23  \n","10            2       True         24  \n","11            2       True         18  \n","12            1       True         12  \n","13            1       True         13  \n","14            1       True          2  \n","15            1       True          6  \n","16            1       True          8  \n","17            1       True         11  \n","18            1       True          9  \n","19            1       True          7  \n","20            2       True         21  \n","21            2       True         19  \n","22            1       True         14  \n","23            1       True          5  \n","24            1       True          3  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["predictor.leaderboard()"]},{"cell_type":"markdown","id":"b184f32f","metadata":{"papermill":{"duration":0.019285,"end_time":"2024-09-13T19:26:21.131322","exception":false,"start_time":"2024-09-13T19:26:21.112037","status":"completed"},"tags":[]},"source":["**What the Leaderboard Shows:**\n","* **Model:** The name of the model that was trained. This can include various types of models such as Random Forest, Gradient Boosting, Neural Networks, etc.\n","* **Time Training:** The time taken to train the model.\n","* **Time Prediction:** The time taken to make predictions with the model.\n","* **Score Validation:** The score (e.g., RMSE) on the validation set, indicating how well the model performs on data it hasnt seen during training.\n","* **Fit Order:** The order in which the models were trained.\n","\n","**Interpreting the Table:**\n","* **WeightedEnsemble_L2:** This is an ensemble model that combines predictions from multiple other models (e.g., LightGBM, CatBoost). It is ranked first due to its lowest RMSE on the validation set (Score_Validation).\n","* **LightGBM_BAG_L1:** A LightGBM model that was also considered. It shows slightly worse performance than the ensemble but may have taken less time to train (Training_Time)."]},{"cell_type":"markdown","id":"2a867035","metadata":{"papermill":{"duration":0.017459,"end_time":"2024-09-13T19:26:21.167201","exception":false,"start_time":"2024-09-13T19:26:21.149742","status":"completed"},"tags":[]},"source":["# Make Predictions"]},{"cell_type":"code","execution_count":9,"id":"412239c1","metadata":{"execution":{"iopub.execute_input":"2024-09-13T19:26:21.217198Z","iopub.status.busy":"2024-09-13T19:26:21.2162Z","iopub.status.idle":"2024-09-13T19:28:41.078303Z","shell.execute_reply":"2024-09-13T19:28:41.077246Z"},"papermill":{"duration":139.889926,"end_time":"2024-09-13T19:28:41.080713","exception":false,"start_time":"2024-09-13T19:26:21.190787","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n"]}],"source":["test_pred = predictor.predict(test_data)"]},{"cell_type":"markdown","id":"b6c3073f","metadata":{"papermill":{"duration":0.020571,"end_time":"2024-09-13T19:28:41.12203","exception":false,"start_time":"2024-09-13T19:28:41.101459","status":"completed"},"tags":[]},"source":["# Submission"]},{"cell_type":"code","execution_count":10,"id":"00465c5d","metadata":{"execution":{"iopub.execute_input":"2024-09-13T19:28:41.165182Z","iopub.status.busy":"2024-09-13T19:28:41.163696Z","iopub.status.idle":"2024-09-13T19:28:41.421829Z","shell.execute_reply":"2024-09-13T19:28:41.421015Z"},"papermill":{"duration":0.281939,"end_time":"2024-09-13T19:28:41.424147","exception":false,"start_time":"2024-09-13T19:28:41.142208","status":"completed"},"tags":[]},"outputs":[],"source":["submission['price'] = test_pred\n","submission.to_csv('submission.csv', index=False)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":9057646,"sourceId":76728,"sourceType":"competition"}],"dockerImageVersionId":30761,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"papermill":{"default_parameters":{},"duration":11013.299882,"end_time":"2024-09-13T19:28:46.665474","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-09-13T16:25:13.365592","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}