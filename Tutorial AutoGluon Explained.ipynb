{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/taimour/s4e9-tutorial-autogluon-explained?scriptVersionId=196330460\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"218ef2b5","metadata":{"papermill":{"duration":0.006282,"end_time":"2024-09-12T06:36:49.504685","exception":false,"start_time":"2024-09-12T06:36:49.498403","status":"completed"},"tags":[]},"source":["# Tutorial - AutoGluon Explained\n","![](https://auto.gluon.ai/stable/_static/autogluon.png)"]},{"cell_type":"markdown","id":"b102cf87","metadata":{"papermill":{"duration":0.006719,"end_time":"2024-09-12T06:36:49.517367","exception":false,"start_time":"2024-09-12T06:36:49.510648","status":"completed"},"tags":[]},"source":["# Installation\n","\n","To keep notebook clean and avoid alot of installation text in notebook, lets use subprocess"]},{"cell_type":"code","execution_count":1,"id":"ff9c91a3","metadata":{"execution":{"iopub.execute_input":"2024-09-12T06:36:49.533591Z","iopub.status.busy":"2024-09-12T06:36:49.533041Z","iopub.status.idle":"2024-09-12T06:38:05.530679Z","shell.execute_reply":"2024-09-12T06:38:05.529675Z"},"papermill":{"duration":76.016188,"end_time":"2024-09-12T06:38:05.540645","exception":false,"start_time":"2024-09-12T06:36:49.524457","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["CompletedProcess(args=['pip', 'install', '-U', 'ipywidgets'], returncode=0, stdout=b'Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.1)\\nCollecting ipywidgets\\n  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\\nRequirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\\nRequirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.21.0)\\nRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\\nCollecting widgetsnbextension~=4.0.12 (from ipywidgets)\\n  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\\nCollecting jupyterlab-widgets~=3.0.12 (from ipywidgets)\\n  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\\nRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.47)\\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.0)\\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\\nDownloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\\n\\x1b[?25l   \\x1b[90m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m \\x1b[32m0.0/139.8 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m\\r\\x1b[2K   \\x1b[90m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m \\x1b[32m139.8/139.8 kB\\x1b[0m \\x1b[31m4.0 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m\\n\\x1b[?25hDownloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\\n\\x1b[?25l   \\x1b[90m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m \\x1b[32m0.0/214.4 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m\\r\\x1b[2K   \\x1b[90m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m \\x1b[32m214.4/214.4 kB\\x1b[0m \\x1b[31m11.1 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m\\n\\x1b[?25hDownloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\\n\\x1b[?25l   \\x1b[90m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m \\x1b[32m0.0/2.3 MB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m\\r\\x1b[2K   \\x1b[91m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m\\x1b[91m\\xe2\\x95\\xb8\\x1b[0m \\x1b[32m2.3/2.3 MB\\x1b[0m \\x1b[31m126.4 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m\\r\\x1b[2K   \\x1b[90m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m \\x1b[32m2.3/2.3 MB\\x1b[0m \\x1b[31m53.9 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m\\n\\x1b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\\n  Attempting uninstall: widgetsnbextension\\n    Found existing installation: widgetsnbextension 3.6.8\\n    Uninstalling widgetsnbextension-3.6.8:\\n      Successfully uninstalled widgetsnbextension-3.6.8\\n  Attempting uninstall: jupyterlab-widgets\\n    Found existing installation: jupyterlab_widgets 3.0.11\\n    Uninstalling jupyterlab_widgets-3.0.11:\\n      Successfully uninstalled jupyterlab_widgets-3.0.11\\n  Attempting uninstall: ipywidgets\\n    Found existing installation: ipywidgets 7.7.1\\n    Uninstalling ipywidgets-7.7.1:\\n      Successfully uninstalled ipywidgets-7.7.1\\nSuccessfully installed ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\\n', stderr=b\"\\x1b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\\nbigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\\nbigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\\nbigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.2 which is incompatible.\\ndataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.8.2 which is incompatible.\\x1b[0m\\x1b[31m\\n\\x1b[0m\")"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import subprocess\n","\n","subprocess.run([\"pip\", \"install\", \"ray==2.10.0\"], capture_output=True)\n","subprocess.run([\"pip\", \"install\", \"autogluon.tabular\"], capture_output=True)\n","subprocess.run([\"pip\", \"install\", \"-U\", \"ipywidgets\"], capture_output=True)"]},{"cell_type":"markdown","id":"1970fc7b","metadata":{"papermill":{"duration":0.006203,"end_time":"2024-09-12T06:38:05.553465","exception":false,"start_time":"2024-09-12T06:38:05.547262","status":"completed"},"tags":[]},"source":["# Import"]},{"cell_type":"code","execution_count":2,"id":"60ce2a74","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-12T06:38:05.568152Z","iopub.status.busy":"2024-09-12T06:38:05.567253Z","iopub.status.idle":"2024-09-12T06:38:08.210336Z","shell.execute_reply":"2024-09-12T06:38:08.209169Z"},"papermill":{"duration":2.653112,"end_time":"2024-09-12T06:38:08.213028","exception":false,"start_time":"2024-09-12T06:38:05.559916","status":"completed"},"tags":[]},"outputs":[],"source":["import pandas as pd\n","from autogluon.tabular import TabularDataset, TabularPredictor"]},{"cell_type":"markdown","id":"a7367a89","metadata":{"papermill":{"duration":0.006476,"end_time":"2024-09-12T06:38:08.226507","exception":false,"start_time":"2024-09-12T06:38:08.220031","status":"completed"},"tags":[]},"source":["# Read Data"]},{"cell_type":"code","execution_count":3,"id":"360d45c9","metadata":{"execution":{"iopub.execute_input":"2024-09-12T06:38:08.242119Z","iopub.status.busy":"2024-09-12T06:38:08.24094Z","iopub.status.idle":"2024-09-12T06:38:10.07399Z","shell.execute_reply":"2024-09-12T06:38:10.073065Z"},"papermill":{"duration":1.843603,"end_time":"2024-09-12T06:38:10.076735","exception":false,"start_time":"2024-09-12T06:38:08.233132","status":"completed"},"tags":[]},"outputs":[],"source":["train_data = pd.read_csv('/kaggle/input/playground-series-s4e9/train.csv').drop('id', axis=1)\n","test_data = pd.read_csv('/kaggle/input/playground-series-s4e9/test.csv').drop('id', axis=1)\n","submission = pd.read_csv('/kaggle/input/playground-series-s4e9/sample_submission.csv')"]},{"cell_type":"markdown","id":"489fc5ae","metadata":{"papermill":{"duration":0.006689,"end_time":"2024-09-12T06:38:10.092551","exception":false,"start_time":"2024-09-12T06:38:10.085862","status":"completed"},"tags":[]},"source":["# View Training and Test data"]},{"cell_type":"code","execution_count":4,"id":"d17b794a","metadata":{"execution":{"iopub.execute_input":"2024-09-12T06:38:10.106863Z","iopub.status.busy":"2024-09-12T06:38:10.106492Z","iopub.status.idle":"2024-09-12T06:38:10.126254Z","shell.execute_reply":"2024-09-12T06:38:10.125139Z"},"papermill":{"duration":0.02962,"end_time":"2024-09-12T06:38:10.128569","exception":false,"start_time":"2024-09-12T06:38:10.098949","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>brand</th>\n","      <th>model</th>\n","      <th>model_year</th>\n","      <th>milage</th>\n","      <th>fuel_type</th>\n","      <th>engine</th>\n","      <th>transmission</th>\n","      <th>ext_col</th>\n","      <th>int_col</th>\n","      <th>accident</th>\n","      <th>clean_title</th>\n","      <th>price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>MINI</td>\n","      <td>Cooper S Base</td>\n","      <td>2007</td>\n","      <td>213000</td>\n","      <td>Gasoline</td>\n","      <td>172.0HP 1.6L 4 Cylinder Engine Gasoline Fuel</td>\n","      <td>A/T</td>\n","      <td>Yellow</td>\n","      <td>Gray</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","      <td>4200</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Lincoln</td>\n","      <td>LS V8</td>\n","      <td>2002</td>\n","      <td>143250</td>\n","      <td>Gasoline</td>\n","      <td>252.0HP 3.9L 8 Cylinder Engine Gasoline Fuel</td>\n","      <td>A/T</td>\n","      <td>Silver</td>\n","      <td>Beige</td>\n","      <td>At least 1 accident or damage reported</td>\n","      <td>Yes</td>\n","      <td>4999</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Chevrolet</td>\n","      <td>Silverado 2500 LT</td>\n","      <td>2002</td>\n","      <td>136731</td>\n","      <td>E85 Flex Fuel</td>\n","      <td>320.0HP 5.3L 8 Cylinder Engine Flex Fuel Capab...</td>\n","      <td>A/T</td>\n","      <td>Blue</td>\n","      <td>Gray</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","      <td>13900</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Genesis</td>\n","      <td>G90 5.0 Ultimate</td>\n","      <td>2017</td>\n","      <td>19500</td>\n","      <td>Gasoline</td>\n","      <td>420.0HP 5.0L 8 Cylinder Engine Gasoline Fuel</td>\n","      <td>Transmission w/Dual Shift Mode</td>\n","      <td>Black</td>\n","      <td>Black</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","      <td>45000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Mercedes-Benz</td>\n","      <td>Metris Base</td>\n","      <td>2021</td>\n","      <td>7388</td>\n","      <td>Gasoline</td>\n","      <td>208.0HP 2.0L 4 Cylinder Engine Gasoline Fuel</td>\n","      <td>7-Speed A/T</td>\n","      <td>Black</td>\n","      <td>Beige</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","      <td>97500</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           brand              model  model_year  milage      fuel_type  \\\n","0           MINI      Cooper S Base        2007  213000       Gasoline   \n","1        Lincoln              LS V8        2002  143250       Gasoline   \n","2      Chevrolet  Silverado 2500 LT        2002  136731  E85 Flex Fuel   \n","3        Genesis   G90 5.0 Ultimate        2017   19500       Gasoline   \n","4  Mercedes-Benz        Metris Base        2021    7388       Gasoline   \n","\n","                                              engine  \\\n","0       172.0HP 1.6L 4 Cylinder Engine Gasoline Fuel   \n","1       252.0HP 3.9L 8 Cylinder Engine Gasoline Fuel   \n","2  320.0HP 5.3L 8 Cylinder Engine Flex Fuel Capab...   \n","3       420.0HP 5.0L 8 Cylinder Engine Gasoline Fuel   \n","4       208.0HP 2.0L 4 Cylinder Engine Gasoline Fuel   \n","\n","                     transmission ext_col int_col  \\\n","0                             A/T  Yellow    Gray   \n","1                             A/T  Silver   Beige   \n","2                             A/T    Blue    Gray   \n","3  Transmission w/Dual Shift Mode   Black   Black   \n","4                     7-Speed A/T   Black   Beige   \n","\n","                                 accident clean_title  price  \n","0                           None reported         Yes   4200  \n","1  At least 1 accident or damage reported         Yes   4999  \n","2                           None reported         Yes  13900  \n","3                           None reported         Yes  45000  \n","4                           None reported         Yes  97500  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["train_data.head()"]},{"cell_type":"code","execution_count":5,"id":"1592c64b","metadata":{"execution":{"iopub.execute_input":"2024-09-12T06:38:10.144206Z","iopub.status.busy":"2024-09-12T06:38:10.143417Z","iopub.status.idle":"2024-09-12T06:38:10.160613Z","shell.execute_reply":"2024-09-12T06:38:10.159574Z"},"papermill":{"duration":0.027288,"end_time":"2024-09-12T06:38:10.162728","exception":false,"start_time":"2024-09-12T06:38:10.13544","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>brand</th>\n","      <th>model</th>\n","      <th>model_year</th>\n","      <th>milage</th>\n","      <th>fuel_type</th>\n","      <th>engine</th>\n","      <th>transmission</th>\n","      <th>ext_col</th>\n","      <th>int_col</th>\n","      <th>accident</th>\n","      <th>clean_title</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Land</td>\n","      <td>Rover LR2 Base</td>\n","      <td>2015</td>\n","      <td>98000</td>\n","      <td>Gasoline</td>\n","      <td>240.0HP 2.0L 4 Cylinder Engine Gasoline Fuel</td>\n","      <td>6-Speed A/T</td>\n","      <td>White</td>\n","      <td>Beige</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Land</td>\n","      <td>Rover Defender SE</td>\n","      <td>2020</td>\n","      <td>9142</td>\n","      <td>Hybrid</td>\n","      <td>395.0HP 3.0L Straight 6 Cylinder Engine Gasoli...</td>\n","      <td>8-Speed A/T</td>\n","      <td>Silver</td>\n","      <td>Black</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Ford</td>\n","      <td>Expedition Limited</td>\n","      <td>2022</td>\n","      <td>28121</td>\n","      <td>Gasoline</td>\n","      <td>3.5L V6 24V PDI DOHC Twin Turbo</td>\n","      <td>10-Speed Automatic</td>\n","      <td>White</td>\n","      <td>Ebony</td>\n","      <td>None reported</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Audi</td>\n","      <td>A6 2.0T Sport</td>\n","      <td>2016</td>\n","      <td>61258</td>\n","      <td>Gasoline</td>\n","      <td>2.0 Liter TFSI</td>\n","      <td>Automatic</td>\n","      <td>Silician Yellow</td>\n","      <td>Black</td>\n","      <td>None reported</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Audi</td>\n","      <td>A6 2.0T Premium Plus</td>\n","      <td>2018</td>\n","      <td>59000</td>\n","      <td>Gasoline</td>\n","      <td>252.0HP 2.0L 4 Cylinder Engine Gasoline Fuel</td>\n","      <td>A/T</td>\n","      <td>Gray</td>\n","      <td>Black</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  brand                 model  model_year  milage fuel_type  \\\n","0  Land        Rover LR2 Base        2015   98000  Gasoline   \n","1  Land     Rover Defender SE        2020    9142    Hybrid   \n","2  Ford    Expedition Limited        2022   28121  Gasoline   \n","3  Audi         A6 2.0T Sport        2016   61258  Gasoline   \n","4  Audi  A6 2.0T Premium Plus        2018   59000  Gasoline   \n","\n","                                              engine        transmission  \\\n","0       240.0HP 2.0L 4 Cylinder Engine Gasoline Fuel         6-Speed A/T   \n","1  395.0HP 3.0L Straight 6 Cylinder Engine Gasoli...         8-Speed A/T   \n","2                    3.5L V6 24V PDI DOHC Twin Turbo  10-Speed Automatic   \n","3                                     2.0 Liter TFSI           Automatic   \n","4       252.0HP 2.0L 4 Cylinder Engine Gasoline Fuel                 A/T   \n","\n","           ext_col int_col       accident clean_title  \n","0            White   Beige  None reported         Yes  \n","1           Silver   Black  None reported         Yes  \n","2            White   Ebony  None reported         NaN  \n","3  Silician Yellow   Black  None reported         NaN  \n","4             Gray   Black  None reported         Yes  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["test_data.head()"]},{"cell_type":"markdown","id":"3a62f3f9","metadata":{"papermill":{"duration":0.007153,"end_time":"2024-09-12T06:38:10.177281","exception":false,"start_time":"2024-09-12T06:38:10.170128","status":"completed"},"tags":[]},"source":["# AutoGluon Introduction\n","\n","AutoGluon is an open-source AutoML framework developed by Amazon that simplifies the process of building machine learning models for various tasks, including tabular data prediction, image classification, text analysis, and more. It automates the entire machine learning pipeline, from data preprocessing to model selection and hyperparameter tuning, making it accessible for users with minimal coding and machine learning expertise. AutoGluon supports both classification and regression problems and leverages powerful ensemble techniques to deliver high-quality models. It also allows users to specify resource constraints, like time limits and hardware availability (GPUs/CPUs), to optimize model training efficiency."]},{"cell_type":"markdown","id":"0708bebc","metadata":{"papermill":{"duration":0.006934,"end_time":"2024-09-12T06:38:10.191325","exception":false,"start_time":"2024-09-12T06:38:10.184391","status":"completed"},"tags":[]},"source":["# AutoGluon Code with Explanation"]},{"cell_type":"code","execution_count":6,"id":"407a798a","metadata":{"execution":{"iopub.execute_input":"2024-09-12T06:38:10.207569Z","iopub.status.busy":"2024-09-12T06:38:10.207154Z","iopub.status.idle":"2024-09-12T16:38:32.948684Z","shell.execute_reply":"2024-09-12T16:38:32.947587Z"},"papermill":{"duration":36022.754283,"end_time":"2024-09-12T16:38:32.952664","exception":false,"start_time":"2024-09-12T06:38:10.198381","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["No path specified. Models will be saved in: \"AutogluonModels/ag-20240912_063810\"\n","2024-09-12 06:38:13,664\tINFO worker.py:1752 -- Started a local Ray instance.\n","\u001b[36m(_ray_fit pid=456)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=456)\u001b[0m [LightGBM] [Fatal] bin size 1669 cannot run on GPU\n","\u001b[36m(_ray_fit pid=456)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=498)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=498)\u001b[0m [LightGBM] [Fatal] bin size 1665 cannot run on GPU\n","\u001b[36m(_ray_fit pid=498)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=540)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=540)\u001b[0m [LightGBM] [Fatal] bin size 1670 cannot run on GPU\n","\u001b[36m(_ray_fit pid=540)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=582)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=582)\u001b[0m [LightGBM] [Fatal] bin size 1666 cannot run on GPU\n","\u001b[36m(_ray_fit pid=582)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=624)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=624)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=624)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=666)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=666)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=666)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=709)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=709)\u001b[0m [LightGBM] [Fatal] bin size 1664 cannot run on GPU\n","\u001b[36m(_ray_fit pid=709)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=751)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=751)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n","\u001b[36m(_ray_fit pid=751)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=883)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=883)\u001b[0m [LightGBM] [Fatal] bin size 1669 cannot run on GPU\n","\u001b[36m(_ray_fit pid=883)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=925)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=925)\u001b[0m [LightGBM] [Fatal] bin size 1665 cannot run on GPU\n","\u001b[36m(_ray_fit pid=925)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=967)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=967)\u001b[0m [LightGBM] [Fatal] bin size 1670 cannot run on GPU\n","\u001b[36m(_ray_fit pid=967)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=1009)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1009)\u001b[0m [LightGBM] [Fatal] bin size 1666 cannot run on GPU\n","\u001b[36m(_ray_fit pid=1009)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=1051)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1051)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=1051)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=1093)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1093)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=1093)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=1135)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1135)\u001b[0m [LightGBM] [Fatal] bin size 1664 cannot run on GPU\n","\u001b[36m(_ray_fit pid=1135)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=1177)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1177)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n","\u001b[36m(_ray_fit pid=1177)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=1323)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1323)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=1399)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1399)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=1475)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1475)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=1551)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1551)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=1627)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1627)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=1703)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1703)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=1779)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1779)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=1855)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1855)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=2035)\u001b[0m No improvement since epoch 0: early stopping\n","\u001b[36m(_ray_fit pid=2035)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2035)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=2088)\u001b[0m No improvement since epoch 0: early stopping\n","\u001b[36m(_ray_fit pid=2088)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2088)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=2141)\u001b[0m No improvement since epoch 4: early stopping\n","\u001b[36m(_ray_fit pid=2141)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2141)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=2194)\u001b[0m No improvement since epoch 4: early stopping\n","\u001b[36m(_ray_fit pid=2194)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2194)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=2247)\u001b[0m No improvement since epoch 2: early stopping\n","\u001b[36m(_ray_fit pid=2247)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2247)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=2300)\u001b[0m No improvement since epoch 0: early stopping\n","\u001b[36m(_ray_fit pid=2300)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2300)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=2353)\u001b[0m No improvement since epoch 0: early stopping\n","\u001b[36m(_ray_fit pid=2353)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2353)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=2406)\u001b[0m No improvement since epoch 1: early stopping\n","\u001b[36m(_ray_fit pid=2406)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2406)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=2549)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:13] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=2549)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=2549)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=2549)\u001b[0m \n","\u001b[36m(_ray_fit pid=2549)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=2549)\u001b[0m \n","\u001b[36m(_ray_fit pid=2549)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=2549)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=2549)\u001b[0m \n","\u001b[36m(_ray_fit pid=2549)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=2549)\u001b[0m \n","\u001b[36m(_ray_fit pid=2549)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=2549)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:14] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=2549)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=2549)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=2549)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=2549)\u001b[0m \n","\u001b[36m(_ray_fit pid=2549)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=2549)\u001b[0m \n","\u001b[36m(_ray_fit pid=2549)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=2593)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:19] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=2593)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n","\u001b[36m(_ray_fit pid=2593)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=2593)\u001b[0m \u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2593)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=2593)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=2593)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=2593)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:20] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=2593)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=2593)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=2593)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=2593)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=2637)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:25] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=2637)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2637)\u001b[0m \u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2637)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=2637)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=2637)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:26] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=2637)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=2637)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:26] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=2637)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=2637)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=2637)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=2637)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=2681)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:31] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=2681)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2681)\u001b[0m \u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2681)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=2681)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=2681)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=2681)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=2681)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:31] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=2681)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=2681)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=2681)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=2681)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=2725)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:37] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=2725)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2725)\u001b[0m \u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2725)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=2725)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=2725)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=2725)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=2725)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:38] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=2725)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=2725)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=2725)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=2725)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=2769)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:43] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=2769)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2769)\u001b[0m \u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2769)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=2769)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=2769)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=2769)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=2769)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:43] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=2769)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=2769)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=2769)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=2769)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=2813)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:48] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=2813)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2813)\u001b[0m \u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2813)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2813)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2813)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:49] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=2813)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=2813)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=2813)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=2813)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=2857)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:54] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=2857)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2857)\u001b[0m \u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2857)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=2857)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=2857)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=2857)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=2857)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [07:18:55] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=2857)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=2857)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=2857)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=2857)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=2991)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=2857)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2857)\u001b[0m \u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2991)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2991)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=3038)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=3038)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=3038)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=3085)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=3085)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=3085)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=3132)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=3132)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=3132)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=3179)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=3179)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=3179)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=3226)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=3226)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=3226)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=3273)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=3273)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=3273)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=3320)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=3320)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=3320)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=3458)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3458)\u001b[0m [LightGBM] [Fatal] bin size 1669 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3458)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3500)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3500)\u001b[0m [LightGBM] [Fatal] bin size 1665 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3500)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3542)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3542)\u001b[0m [LightGBM] [Fatal] bin size 1670 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3542)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3584)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3584)\u001b[0m [LightGBM] [Fatal] bin size 1666 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3584)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3626)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3626)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3626)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3668)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3668)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3668)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3710)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3710)\u001b[0m [LightGBM] [Fatal] bin size 1664 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3710)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3752)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3752)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3752)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3884)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3884)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=3960)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3960)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=4036)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4036)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=4112)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4112)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=4188)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4188)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=4264)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4264)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=4340)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4340)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=4416)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4416)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=4582)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=4582)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=4582)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=4629)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=4629)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=4629)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=4676)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=4676)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=4676)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=4723)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=4723)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=4723)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=4770)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=4770)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=4770)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=4817)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=4817)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=4817)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=4864)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=4864)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=4864)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=4911)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=4911)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=4911)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=5048)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=5048)\u001b[0m [LightGBM] [Fatal] bin size 1669 cannot run on GPU\n","\u001b[36m(_ray_fit pid=5048)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=5090)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=5090)\u001b[0m [LightGBM] [Fatal] bin size 1665 cannot run on GPU\n","\u001b[36m(_ray_fit pid=5090)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=5132)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=5132)\u001b[0m [LightGBM] [Fatal] bin size 1670 cannot run on GPU\n","\u001b[36m(_ray_fit pid=5132)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=5174)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=5174)\u001b[0m [LightGBM] [Fatal] bin size 1666 cannot run on GPU\n","\u001b[36m(_ray_fit pid=5174)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=5216)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=5216)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=5216)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=5258)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=5258)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=5258)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=5300)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=5300)\u001b[0m [LightGBM] [Fatal] bin size 1664 cannot run on GPU\n","\u001b[36m(_ray_fit pid=5300)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=5343)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=5343)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n","\u001b[36m(_ray_fit pid=5343)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=5475)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 5)\n","\u001b[36m(_ray_fit pid=5475)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=5475)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=5528)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 5)\n","\u001b[36m(_ray_fit pid=5528)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=5528)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=5581)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 5)\n","\u001b[36m(_ray_fit pid=5581)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=5581)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=5634)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 5)\n","\u001b[36m(_ray_fit pid=5634)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=5634)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=5687)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 5)\n","\u001b[36m(_ray_fit pid=5687)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=5687)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=5740)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 5)\n","\u001b[36m(_ray_fit pid=5740)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=5740)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=5793)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 5)\n","\u001b[36m(_ray_fit pid=5793)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=5793)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=5846)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 5)\n","\u001b[36m(_ray_fit pid=5846)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=5846)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=5989)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=5989)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=6065)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=6065)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=6141)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=6141)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=6217)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=6217)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=6293)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=6293)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=6369)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=6369)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=6445)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=6445)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=6522)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=6522)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=6688)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=6688)\u001b[0m [LightGBM] [Fatal] bin size 1669 cannot run on GPU\n","\u001b[36m(_ray_fit pid=6688)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=6688)\u001b[0m \tRan out of time, early stopping on iteration 14. Best iteration is:\n","\u001b[36m(_ray_fit pid=6688)\u001b[0m \t[14]\tvalid_set's rmse: 85910.3\n","\u001b[36m(_ray_fit pid=6730)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=6730)\u001b[0m [LightGBM] [Fatal] bin size 1665 cannot run on GPU\n","\u001b[36m(_ray_fit pid=6730)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=6730)\u001b[0m \tRan out of time, early stopping on iteration 45. Best iteration is:\n","\u001b[36m(_ray_fit pid=6730)\u001b[0m \t[45]\tvalid_set's rmse: 85280.6\n","\u001b[36m(_ray_fit pid=6772)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=6772)\u001b[0m [LightGBM] [Fatal] bin size 1670 cannot run on GPU\n","\u001b[36m(_ray_fit pid=6772)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=6772)\u001b[0m \tRan out of time, early stopping on iteration 57. Best iteration is:\n","\u001b[36m(_ray_fit pid=6772)\u001b[0m \t[57]\tvalid_set's rmse: 71359.4\n","\u001b[36m(_ray_fit pid=6814)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=6814)\u001b[0m [LightGBM] [Fatal] bin size 1666 cannot run on GPU\n","\u001b[36m(_ray_fit pid=6814)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=6814)\u001b[0m \tRan out of time, early stopping on iteration 57. Best iteration is:\n","\u001b[36m(_ray_fit pid=6814)\u001b[0m \t[57]\tvalid_set's rmse: 80662.2\n","\u001b[36m(_ray_fit pid=6856)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=6856)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=6856)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=6856)\u001b[0m \tRan out of time, early stopping on iteration 57. Best iteration is:\n","\u001b[36m(_ray_fit pid=6856)\u001b[0m \t[57]\tvalid_set's rmse: 69531.7\n","\u001b[36m(_ray_fit pid=6898)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=6898)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=6898)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=6898)\u001b[0m \tRan out of time, early stopping on iteration 58. Best iteration is:\n","\u001b[36m(_ray_fit pid=6898)\u001b[0m \t[58]\tvalid_set's rmse: 71286.6\n","\u001b[36m(_ray_fit pid=6940)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=6940)\u001b[0m [LightGBM] [Fatal] bin size 1664 cannot run on GPU\n","\u001b[36m(_ray_fit pid=6940)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=6940)\u001b[0m \tRan out of time, early stopping on iteration 57. Best iteration is:\n","\u001b[36m(_ray_fit pid=6940)\u001b[0m \t[57]\tvalid_set's rmse: 64013.8\n","\u001b[36m(_ray_fit pid=6982)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=6982)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n","\u001b[36m(_ray_fit pid=6982)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=6982)\u001b[0m \tRan out of time, early stopping on iteration 56. Best iteration is:\n","\u001b[36m(_ray_fit pid=6982)\u001b[0m \t[56]\tvalid_set's rmse: 72869.3\n","\u001b[36m(_ray_fit pid=7120)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=7120)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=7120)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=7162)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=7162)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n","\u001b[36m(_ray_fit pid=7162)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=7204)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=7204)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n","\u001b[36m(_ray_fit pid=7204)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=7246)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=7246)\u001b[0m [LightGBM] [Fatal] bin size 1666 cannot run on GPU\n","\u001b[36m(_ray_fit pid=7246)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=7288)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=7288)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=7288)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=7330)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=7330)\u001b[0m [LightGBM] [Fatal] bin size 1670 cannot run on GPU\n","\u001b[36m(_ray_fit pid=7330)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=7372)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=7372)\u001b[0m [LightGBM] [Fatal] bin size 1665 cannot run on GPU\n","\u001b[36m(_ray_fit pid=7372)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=7414)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=7414)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=7414)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=7552)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=7552)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=7552)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=7594)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=7594)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n","\u001b[36m(_ray_fit pid=7594)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=7636)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=7636)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n","\u001b[36m(_ray_fit pid=7636)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=7678)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=7678)\u001b[0m [LightGBM] [Fatal] bin size 1666 cannot run on GPU\n","\u001b[36m(_ray_fit pid=7678)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=7720)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=7720)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=7720)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=7762)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=7762)\u001b[0m [LightGBM] [Fatal] bin size 1670 cannot run on GPU\n","\u001b[36m(_ray_fit pid=7762)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=7804)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=7804)\u001b[0m [LightGBM] [Fatal] bin size 1665 cannot run on GPU\n","\u001b[36m(_ray_fit pid=7804)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=7846)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=7846)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=7846)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=7998)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=7998)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=8068)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=8068)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=8141)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=8141)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=8211)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=8211)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=8288)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=8288)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=8358)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=8358)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=8428)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=8428)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=8504)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=8504)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=8685)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=8685)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=8738)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 13)\n","\u001b[36m(_ray_fit pid=8738)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=8738)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=8791)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=8791)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=8844)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=8844)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=8897)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=8897)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=8950)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=8950)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=9003)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=9003)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=9056)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=9056)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=9205)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:03:34] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=9205)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=9205)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:03:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=9205)\u001b[0m \n","\u001b[36m(_ray_fit pid=9205)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=9205)\u001b[0m \n","\u001b[36m(_ray_fit pid=9205)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=9205)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:03:35] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=9205)\u001b[0m \n","\u001b[36m(_ray_fit pid=9205)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=9205)\u001b[0m \n","\u001b[36m(_ray_fit pid=9205)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=9205)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:03:35] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=9205)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=9205)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=9205)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=9205)\u001b[0m \n","\u001b[36m(_ray_fit pid=9205)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=9205)\u001b[0m \n","\u001b[36m(_ray_fit pid=9205)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=9249)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:03:40] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=9249)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=9249)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:03:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=9249)\u001b[0m \u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=9249)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=9249)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:03:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=9249)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=9249)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:03:41] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=9249)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=9249)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=9249)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=9249)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=9293)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:03:46] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=9293)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=9293)\u001b[0m \u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=9293)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:03:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=9293)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=9293)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:03:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=9293)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=9293)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:03:47] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=9293)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=9293)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=9293)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=9293)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=9337)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:03:53] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=9337)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=9337)\u001b[0m \u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=9337)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:03:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=9337)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=9337)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:03:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=9337)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=9337)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:03:54] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=9337)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=9337)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=9337)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=9337)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=9381)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:03:59] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=9381)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=9381)\u001b[0m \u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=9381)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:03:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=9381)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=9381)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:04:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=9381)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=9381)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:04:00] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=9381)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=9381)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=9381)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=9381)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=9425)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:04:05] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=9425)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=9425)\u001b[0m \u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=9425)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:04:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=9425)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=9425)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:04:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=9425)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=9425)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:04:06] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=9425)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=9425)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=9425)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=9425)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=9469)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:04:12] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=9469)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=9469)\u001b[0m \u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=9469)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:04:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=9469)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=9469)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:04:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=9469)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=9469)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:04:13] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=9469)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=9469)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=9469)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=9469)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=9513)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:04:18] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=9513)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=9513)\u001b[0m \u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=9513)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:04:18] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=9513)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=9513)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:04:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=9513)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=9513)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [09:04:19] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=9513)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=9513)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=9513)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=9513)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=9653)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=9513)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=9513)\u001b[0m \u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=9653)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 6)\n","\u001b[36m(_ray_fit pid=9653)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=9653)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=9700)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=9700)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=9700)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=9747)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=9747)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 7)\n","\u001b[36m(_ray_fit pid=9747)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=9747)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=9794)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=9794)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 7)\n","\u001b[36m(_ray_fit pid=9794)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=9794)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=9841)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=9841)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 7)\n","\u001b[36m(_ray_fit pid=9841)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=9841)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=9888)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=9888)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 7)\n","\u001b[36m(_ray_fit pid=9888)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=9888)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=9935)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=9935)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=9935)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=9982)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=9982)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=9982)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=187)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=187)\u001b[0m   return torch.load(io.BytesIO(b))\n"]}],"source":["predictor = TabularPredictor(\n","    label='price',             # Target column that needs to be predicted (dependent variable)\n","    eval_metric='rmse',        # Evaluation metric (Root Mean Squared Error) used to judge the models performance\n","    problem_type='regression'  # Specifying this is a regression problem\n",").fit(\n","    train_data,                  # The training dataset containing features and the target (price)\n","    presets='best_quality',    # The preset configuration for optimal quality (though it may take more time)\n","    time_limit=3600*10,      # Time limit for training (10 hours = 3600 seconds/hour * 10 hours)\n","    verbosity=0,               # Level of logging information (0 is used to avoid alot of text in notebook)\n","    excluded_model_types=['KNN'], # Exclude K-Nearest Neighbors models from training\n","    ag_args_fit={\n","        'num_gpus': 2,          # Use 2 GPUs if available for model training\n","        'num_cpus': 4           # Use 4 CPUs for model training\n","    }\n",")"]},{"cell_type":"markdown","id":"66b8174a","metadata":{"papermill":{"duration":0.031317,"end_time":"2024-09-12T16:38:33.024603","exception":false,"start_time":"2024-09-12T16:38:32.993286","status":"completed"},"tags":[]},"source":["* **label='price':** The column name 'price' is the target (dependent variable) to be predicted.\n","* **eval_metric='rmse':** The Root Mean Squared Error (RMSE) is chosen as the evaluation metric, which is common for regression tasks.\n","* **problem_type='regression':** Specifies that the task is a regression task (i.e., predicting continuous values).\n","* **train_data:** This is the DataFrame containing the training data with both features and the target (price).\n","* **presets='best_quality':** This preset prioritizes accuracy over training speed. It will try many models and techniques to ensure the highest possible quality.\n","* **time_limit=3600*10:** Limits the model training process to a maximum of 10 hours.\n","* **verbosity=0:** Specifies the verbosity level for logging. Higher values will show more details about the training process. To avoid alot of text in notebook we will use 0.\n","* **excluded_model_types=['KNN']:** K-Nearest Neighbors (KNN) models are excluded from being considered during training.\n","* **ag_args_fit:** This argument allows you to pass configuration options to the fitting process:\n","* **num_gpus=2:** The model will utilize 2 GPUs for training if available, speeding up the process for certain algorithms.\n","* **num_cpus=4:** The model will use 4 CPU cores during training."]},{"cell_type":"code","execution_count":7,"id":"4a8bbc87","metadata":{"execution":{"iopub.execute_input":"2024-09-12T16:38:33.094064Z","iopub.status.busy":"2024-09-12T16:38:33.092801Z","iopub.status.idle":"2024-09-12T16:38:33.964283Z","shell.execute_reply":"2024-09-12T16:38:33.963184Z"},"papermill":{"duration":0.908961,"end_time":"2024-09-12T16:38:33.966673","exception":false,"start_time":"2024-09-12T16:38:33.057712","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["*** Summary of fit() ***\n","Estimated performance of each model:\n","                          model     score_val              eval_metric  pred_time_val      fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n","0           WeightedEnsemble_L3 -72488.637193  root_mean_squared_error     156.222369  21327.878922                0.003391           0.756852            3       True         52\n","1               CatBoost_BAG_L2 -72534.730387  root_mean_squared_error     129.351318  17945.003625                0.862696          91.057286            2       True         39\n","2           WeightedEnsemble_L2 -72552.964827  root_mean_squared_error      38.508065   9617.831020                0.004266           1.009948            2       True         35\n","3          CatBoost_r177_BAG_L2 -72564.952583  root_mean_squared_error     129.170103  17931.880231                0.681480          77.933892            2       True         45\n","4           LightGBM_r96_BAG_L2 -72598.539278  root_mean_squared_error     129.589986  17957.948561                1.101363         104.002222            2       True         50\n","5             LightGBMXT_BAG_L2 -72661.834380  root_mean_squared_error     129.009820  17932.420630                0.521198          78.474292            2       True         36\n","6           CatBoost_r13_BAG_L1 -72766.972850  root_mean_squared_error       3.816768    314.805590                3.816768         314.805590            1       True         21\n","7            CatBoost_r9_BAG_L1 -72805.334784  root_mean_squared_error       0.960838     84.314971                0.960838          84.314971            1       True         14\n","8               CatBoost_BAG_L1 -72812.796073  root_mean_squared_error       1.411836    132.196657                1.411836         132.196657            1       True          4\n","9           CatBoost_r50_BAG_L1 -72822.085879  root_mean_squared_error       0.783241     65.064961                0.783241          65.064961            1       True         29\n","10         CatBoost_r177_BAG_L1 -72844.316077  root_mean_squared_error       1.037409     97.259647                1.037409          97.259647            1       True         10\n","11         CatBoost_r137_BAG_L1 -72844.496294  root_mean_squared_error       1.446389    137.021951                1.446389         137.021951            1       True         19\n","12       NeuralNetFastAI_BAG_L2 -72864.238026  root_mean_squared_error     132.801277  19709.289176                4.312655        1855.342837            2       True         41\n","13          LightGBM_r96_BAG_L1 -72867.276922  root_mean_squared_error       2.990662    112.915504                2.990662         112.915504            1       True         15\n","14            LightGBMXT_BAG_L1 -72917.481425  root_mean_squared_error       0.790484     64.146789                0.790484          64.146789            1       True          1\n","15           CatBoost_r9_BAG_L2 -72933.404539  root_mean_squared_error     129.269627  17917.064875                0.781004          63.118537            2       True         49\n","16         LightGBM_r131_BAG_L2 -72981.744018  root_mean_squared_error     129.557734  17971.214538                1.069111         117.268199            2       True         47\n","17         LightGBM_r130_BAG_L1 -72991.827008  root_mean_squared_error       0.605696     66.568236                0.605696          66.568236            1       True         27\n","18               XGBoost_BAG_L2 -73009.771517  root_mean_squared_error     130.255580  17913.612977                1.766957          59.666638            2       True         42\n","19        NeuralNetTorch_BAG_L2 -73012.369189  root_mean_squared_error     131.708359  18799.421771                3.219737         945.475432            2       True         43\n","20         LightGBM_r188_BAG_L1 -73025.414165  root_mean_squared_error       1.062339     77.245158                1.062339          77.245158            1       True         23\n","21              LightGBM_BAG_L2 -73054.033238  root_mean_squared_error     128.958337  17928.333816                0.469715          74.387477            2       True         37\n","22    NeuralNetTorch_r79_BAG_L2 -73077.282358  root_mean_squared_error     131.834625  18785.099875                3.346003         931.153536            2       True         46\n","23         LightGBM_r131_BAG_L1 -73119.010616  root_mean_squared_error       1.535072    100.106019                1.535072         100.106019            1       True         12\n","24  NeuralNetFastAI_r145_BAG_L1 -73166.785583  root_mean_squared_error       7.947071   3694.630528                7.947071        3694.630528            1       True         24\n","25       NeuralNetFastAI_BAG_L1 -73204.822678  root_mean_squared_error       4.113538   1776.686076                4.113538        1776.686076            1       True          6\n","26              LightGBM_BAG_L1 -73211.006130  root_mean_squared_error       0.467164     59.917255                0.467164          59.917255            1       True          2\n","27  NeuralNetFastAI_r191_BAG_L1 -73230.812248  root_mean_squared_error       4.120958   1898.687822                4.120958        1898.687822            1       True         13\n","28           XGBoost_r89_BAG_L1 -73256.835521  root_mean_squared_error       1.252681     48.291197                1.252681          48.291197            1       True         25\n","29  NeuralNetFastAI_r102_BAG_L1 -73304.278592  root_mean_squared_error       1.024712    329.587118                1.024712         329.587118            1       True         20\n","30       ExtraTrees_r172_BAG_L1 -73338.917482  root_mean_squared_error      13.637557    284.051960               13.637557         284.051960            1       True         32\n","31  NeuralNetFastAI_r191_BAG_L2 -73401.062963  root_mean_squared_error     132.870752  19123.225087                4.382129        1269.278749            2       True         48\n","32        NeuralNetTorch_BAG_L1 -73419.679730  root_mean_squared_error       1.336806   1457.581299                1.336806        1457.581299            1       True          8\n","33    NeuralNetTorch_r79_BAG_L1 -73457.894931  root_mean_squared_error       1.493420   1102.423810                1.493420        1102.423810            1       True         11\n","34         LightGBMLarge_BAG_L2 -73470.109311  root_mean_squared_error     129.192133  17951.556773                0.703511          97.610435            2       True         44\n","35         LightGBMLarge_BAG_L1 -73620.198965  root_mean_squared_error       0.644322     71.662214                0.644322          71.662214            1       True          9\n","36   NeuralNetFastAI_r11_BAG_L1 -73634.830372  root_mean_squared_error       7.607835   1706.814909                7.607835        1706.814909            1       True         30\n","37               XGBoost_BAG_L1 -73649.378532  root_mean_squared_error       1.171746     47.108245                1.171746          47.108245            1       True          7\n","38           XGBoost_r33_BAG_L1 -73705.454232  root_mean_squared_error       1.420637     65.421180                1.420637          65.421180            1       True         17\n","39  NeuralNetFastAI_r103_BAG_L1 -73760.151896  root_mean_squared_error       4.147008    134.938038                4.147008         134.938038            1       True         34\n","40         ExtraTreesMSE_BAG_L2 -73921.660451  root_mean_squared_error     146.722529  18331.244292               18.233906         477.297953            2       True         40\n","41          XGBoost_r194_BAG_L1 -74016.457249  root_mean_squared_error       0.639613     45.868675                0.639613          45.868675            1       True         31\n","42          CatBoost_r69_BAG_L1 -74103.980294  root_mean_squared_error       0.395204     50.021456                0.395204          50.021456            1       True         33\n","43       RandomForestMSE_BAG_L2 -74570.856246  root_mean_squared_error     149.627795  20317.326983               21.139173        2463.380644            2       True         38\n","44        ExtraTrees_r42_BAG_L1 -76874.413863  root_mean_squared_error      13.238459    213.579978               13.238459         213.579978            1       True         18\n","45     RandomForest_r195_BAG_L1 -77292.027794  root_mean_squared_error      16.845897    351.529874               16.845897         351.529874            1       True         22\n","46         ExtraTreesMSE_BAG_L1 -77344.072883  root_mean_squared_error      12.943583    267.960581               12.943583         267.960581            1       True          5\n","47       RandomForestMSE_BAG_L1 -78153.007850  root_mean_squared_error      13.228894    365.255172               13.228894         365.255172            1       True          3\n","48    NeuralNetTorch_r30_BAG_L1 -80079.180242  root_mean_squared_error       1.652692   1362.589340                1.652692        1362.589340            1       True         26\n","49    NeuralNetTorch_r22_BAG_L1 -90209.188547  root_mean_squared_error       1.351551    658.290344                1.351551         658.290344            1       True         16\n","50    NeuralNetTorch_r86_BAG_L1 -90209.558475  root_mean_squared_error       1.366541    609.403784                1.366541         609.403784            1       True         28\n","51    NeuralNetTorch_r22_BAG_L2 -90921.513627  root_mean_squared_error     131.704071  17989.742940                3.215448         135.796602            2       True         51\n","Number of models trained: 52\n","Types of models trained:\n","{'StackerEnsembleModel_LGB', 'StackerEnsembleModel_RF', 'WeightedEnsembleModel', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_TabularNeuralNetTorch', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_XT'}\n","Bagging used: True  (with 8 folds)\n","Multi-layer stack-ensembling used: True  (with 3 levels)\n","Feature Metadata (Processed):\n","(raw dtype, special dtypes):\n","('category', [])                    :  7 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n","('category', ['text_as_category'])  :  1 | ['engine']\n","('int', [])                         :  2 | ['model_year', 'milage']\n","('int', ['binned', 'text_special']) : 11 | ['engine.char_count', 'engine.word_count', 'engine.capital_ratio', 'engine.lower_ratio', 'engine.digit_ratio', ...]\n","('int', ['bool'])                   :  1 | ['clean_title']\n","('int', ['text_ngram'])             : 65 | ['__nlp__.0hp', '__nlp__.0hp 0l', '__nlp__.0hp 0l cylinder', '__nlp__.0hp 0l straight', '__nlp__.0hp 0l v6', ...]\n","Plot summary of models saved to file: AutogluonModels/ag-20240912_063810SummaryOfModels.html\n","*** End of fit() summary ***\n"]}],"source":["results = predictor.fit_summary()"]},{"cell_type":"markdown","id":"fdc68b1b","metadata":{"papermill":{"duration":0.033352,"end_time":"2024-09-12T16:38:34.034011","exception":false,"start_time":"2024-09-12T16:38:34.000659","status":"completed"},"tags":[]},"source":["* **fit_summary():** After training is complete, this method outputs a summary of the models trained, their performance, and additional statistics. The results object will contain information such as the leaderboard of model performance, training times, and which model was selected as the best for predictions."]},{"cell_type":"markdown","id":"f74d1934","metadata":{"papermill":{"duration":0.034685,"end_time":"2024-09-12T16:38:34.102679","exception":false,"start_time":"2024-09-12T16:38:34.067994","status":"completed"},"tags":[]},"source":["# Models Leaderboard"]},{"cell_type":"code","execution_count":8,"id":"f309f7b3","metadata":{"execution":{"iopub.execute_input":"2024-09-12T16:38:34.172342Z","iopub.status.busy":"2024-09-12T16:38:34.17187Z","iopub.status.idle":"2024-09-12T16:38:34.223465Z","shell.execute_reply":"2024-09-12T16:38:34.22228Z"},"papermill":{"duration":0.090122,"end_time":"2024-09-12T16:38:34.226641","exception":false,"start_time":"2024-09-12T16:38:34.136519","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>score_val</th>\n","      <th>eval_metric</th>\n","      <th>pred_time_val</th>\n","      <th>fit_time</th>\n","      <th>pred_time_val_marginal</th>\n","      <th>fit_time_marginal</th>\n","      <th>stack_level</th>\n","      <th>can_infer</th>\n","      <th>fit_order</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>WeightedEnsemble_L3</td>\n","      <td>-72488.637193</td>\n","      <td>root_mean_squared_error</td>\n","      <td>156.222369</td>\n","      <td>21327.878922</td>\n","      <td>0.003391</td>\n","      <td>0.756852</td>\n","      <td>3</td>\n","      <td>True</td>\n","      <td>52</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CatBoost_BAG_L2</td>\n","      <td>-72534.730387</td>\n","      <td>root_mean_squared_error</td>\n","      <td>129.351318</td>\n","      <td>17945.003625</td>\n","      <td>0.862696</td>\n","      <td>91.057286</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>39</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>WeightedEnsemble_L2</td>\n","      <td>-72552.964827</td>\n","      <td>root_mean_squared_error</td>\n","      <td>38.508065</td>\n","      <td>9617.831020</td>\n","      <td>0.004266</td>\n","      <td>1.009948</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>35</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>CatBoost_r177_BAG_L2</td>\n","      <td>-72564.952583</td>\n","      <td>root_mean_squared_error</td>\n","      <td>129.170103</td>\n","      <td>17931.880231</td>\n","      <td>0.681480</td>\n","      <td>77.933892</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>LightGBM_r96_BAG_L2</td>\n","      <td>-72598.539278</td>\n","      <td>root_mean_squared_error</td>\n","      <td>129.589986</td>\n","      <td>17957.948561</td>\n","      <td>1.101363</td>\n","      <td>104.002222</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>LightGBMXT_BAG_L2</td>\n","      <td>-72661.834380</td>\n","      <td>root_mean_squared_error</td>\n","      <td>129.009820</td>\n","      <td>17932.420630</td>\n","      <td>0.521198</td>\n","      <td>78.474292</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>CatBoost_r13_BAG_L1</td>\n","      <td>-72766.972850</td>\n","      <td>root_mean_squared_error</td>\n","      <td>3.816768</td>\n","      <td>314.805590</td>\n","      <td>3.816768</td>\n","      <td>314.805590</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>CatBoost_r9_BAG_L1</td>\n","      <td>-72805.334784</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.960838</td>\n","      <td>84.314971</td>\n","      <td>0.960838</td>\n","      <td>84.314971</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>CatBoost_BAG_L1</td>\n","      <td>-72812.796073</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1.411836</td>\n","      <td>132.196657</td>\n","      <td>1.411836</td>\n","      <td>132.196657</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>CatBoost_r50_BAG_L1</td>\n","      <td>-72822.085879</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.783241</td>\n","      <td>65.064961</td>\n","      <td>0.783241</td>\n","      <td>65.064961</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>CatBoost_r177_BAG_L1</td>\n","      <td>-72844.316077</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1.037409</td>\n","      <td>97.259647</td>\n","      <td>1.037409</td>\n","      <td>97.259647</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>CatBoost_r137_BAG_L1</td>\n","      <td>-72844.496294</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1.446389</td>\n","      <td>137.021951</td>\n","      <td>1.446389</td>\n","      <td>137.021951</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>NeuralNetFastAI_BAG_L2</td>\n","      <td>-72864.238026</td>\n","      <td>root_mean_squared_error</td>\n","      <td>132.801277</td>\n","      <td>19709.289176</td>\n","      <td>4.312655</td>\n","      <td>1855.342837</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>41</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>LightGBM_r96_BAG_L1</td>\n","      <td>-72867.276922</td>\n","      <td>root_mean_squared_error</td>\n","      <td>2.990662</td>\n","      <td>112.915504</td>\n","      <td>2.990662</td>\n","      <td>112.915504</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>LightGBMXT_BAG_L1</td>\n","      <td>-72917.481425</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.790484</td>\n","      <td>64.146789</td>\n","      <td>0.790484</td>\n","      <td>64.146789</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>CatBoost_r9_BAG_L2</td>\n","      <td>-72933.404539</td>\n","      <td>root_mean_squared_error</td>\n","      <td>129.269627</td>\n","      <td>17917.064875</td>\n","      <td>0.781004</td>\n","      <td>63.118537</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>49</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>LightGBM_r131_BAG_L2</td>\n","      <td>-72981.744018</td>\n","      <td>root_mean_squared_error</td>\n","      <td>129.557734</td>\n","      <td>17971.214538</td>\n","      <td>1.069111</td>\n","      <td>117.268199</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>47</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>LightGBM_r130_BAG_L1</td>\n","      <td>-72991.827008</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.605696</td>\n","      <td>66.568236</td>\n","      <td>0.605696</td>\n","      <td>66.568236</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>27</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>XGBoost_BAG_L2</td>\n","      <td>-73009.771517</td>\n","      <td>root_mean_squared_error</td>\n","      <td>130.255580</td>\n","      <td>17913.612977</td>\n","      <td>1.766957</td>\n","      <td>59.666638</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>42</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>NeuralNetTorch_BAG_L2</td>\n","      <td>-73012.369189</td>\n","      <td>root_mean_squared_error</td>\n","      <td>131.708359</td>\n","      <td>18799.421771</td>\n","      <td>3.219737</td>\n","      <td>945.475432</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>43</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>LightGBM_r188_BAG_L1</td>\n","      <td>-73025.414165</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1.062339</td>\n","      <td>77.245158</td>\n","      <td>1.062339</td>\n","      <td>77.245158</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>LightGBM_BAG_L2</td>\n","      <td>-73054.033238</td>\n","      <td>root_mean_squared_error</td>\n","      <td>128.958337</td>\n","      <td>17928.333816</td>\n","      <td>0.469715</td>\n","      <td>74.387477</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>37</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>NeuralNetTorch_r79_BAG_L2</td>\n","      <td>-73077.282358</td>\n","      <td>root_mean_squared_error</td>\n","      <td>131.834625</td>\n","      <td>18785.099875</td>\n","      <td>3.346003</td>\n","      <td>931.153536</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>LightGBM_r131_BAG_L1</td>\n","      <td>-73119.010616</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1.535072</td>\n","      <td>100.106019</td>\n","      <td>1.535072</td>\n","      <td>100.106019</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>NeuralNetFastAI_r145_BAG_L1</td>\n","      <td>-73166.785583</td>\n","      <td>root_mean_squared_error</td>\n","      <td>7.947071</td>\n","      <td>3694.630528</td>\n","      <td>7.947071</td>\n","      <td>3694.630528</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>NeuralNetFastAI_BAG_L1</td>\n","      <td>-73204.822678</td>\n","      <td>root_mean_squared_error</td>\n","      <td>4.113538</td>\n","      <td>1776.686076</td>\n","      <td>4.113538</td>\n","      <td>1776.686076</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>LightGBM_BAG_L1</td>\n","      <td>-73211.006130</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.467164</td>\n","      <td>59.917255</td>\n","      <td>0.467164</td>\n","      <td>59.917255</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>NeuralNetFastAI_r191_BAG_L1</td>\n","      <td>-73230.812248</td>\n","      <td>root_mean_squared_error</td>\n","      <td>4.120958</td>\n","      <td>1898.687822</td>\n","      <td>4.120958</td>\n","      <td>1898.687822</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>XGBoost_r89_BAG_L1</td>\n","      <td>-73256.835521</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1.252681</td>\n","      <td>48.291197</td>\n","      <td>1.252681</td>\n","      <td>48.291197</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>25</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>NeuralNetFastAI_r102_BAG_L1</td>\n","      <td>-73304.278592</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1.024712</td>\n","      <td>329.587118</td>\n","      <td>1.024712</td>\n","      <td>329.587118</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>ExtraTrees_r172_BAG_L1</td>\n","      <td>-73338.917482</td>\n","      <td>root_mean_squared_error</td>\n","      <td>13.637557</td>\n","      <td>284.051960</td>\n","      <td>13.637557</td>\n","      <td>284.051960</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>NeuralNetFastAI_r191_BAG_L2</td>\n","      <td>-73401.062963</td>\n","      <td>root_mean_squared_error</td>\n","      <td>132.870752</td>\n","      <td>19123.225087</td>\n","      <td>4.382129</td>\n","      <td>1269.278749</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>48</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>NeuralNetTorch_BAG_L1</td>\n","      <td>-73419.679730</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1.336806</td>\n","      <td>1457.581299</td>\n","      <td>1.336806</td>\n","      <td>1457.581299</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>NeuralNetTorch_r79_BAG_L1</td>\n","      <td>-73457.894931</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1.493420</td>\n","      <td>1102.423810</td>\n","      <td>1.493420</td>\n","      <td>1102.423810</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>LightGBMLarge_BAG_L2</td>\n","      <td>-73470.109311</td>\n","      <td>root_mean_squared_error</td>\n","      <td>129.192133</td>\n","      <td>17951.556773</td>\n","      <td>0.703511</td>\n","      <td>97.610435</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>44</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>LightGBMLarge_BAG_L1</td>\n","      <td>-73620.198965</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.644322</td>\n","      <td>71.662214</td>\n","      <td>0.644322</td>\n","      <td>71.662214</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>NeuralNetFastAI_r11_BAG_L1</td>\n","      <td>-73634.830372</td>\n","      <td>root_mean_squared_error</td>\n","      <td>7.607835</td>\n","      <td>1706.814909</td>\n","      <td>7.607835</td>\n","      <td>1706.814909</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>XGBoost_BAG_L1</td>\n","      <td>-73649.378532</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1.171746</td>\n","      <td>47.108245</td>\n","      <td>1.171746</td>\n","      <td>47.108245</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>XGBoost_r33_BAG_L1</td>\n","      <td>-73705.454232</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1.420637</td>\n","      <td>65.421180</td>\n","      <td>1.420637</td>\n","      <td>65.421180</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>NeuralNetFastAI_r103_BAG_L1</td>\n","      <td>-73760.151896</td>\n","      <td>root_mean_squared_error</td>\n","      <td>4.147008</td>\n","      <td>134.938038</td>\n","      <td>4.147008</td>\n","      <td>134.938038</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>34</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>ExtraTreesMSE_BAG_L2</td>\n","      <td>-73921.660451</td>\n","      <td>root_mean_squared_error</td>\n","      <td>146.722529</td>\n","      <td>18331.244292</td>\n","      <td>18.233906</td>\n","      <td>477.297953</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>XGBoost_r194_BAG_L1</td>\n","      <td>-74016.457249</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.639613</td>\n","      <td>45.868675</td>\n","      <td>0.639613</td>\n","      <td>45.868675</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>CatBoost_r69_BAG_L1</td>\n","      <td>-74103.980294</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.395204</td>\n","      <td>50.021456</td>\n","      <td>0.395204</td>\n","      <td>50.021456</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>RandomForestMSE_BAG_L2</td>\n","      <td>-74570.856246</td>\n","      <td>root_mean_squared_error</td>\n","      <td>149.627795</td>\n","      <td>20317.326983</td>\n","      <td>21.139173</td>\n","      <td>2463.380644</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>38</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>ExtraTrees_r42_BAG_L1</td>\n","      <td>-76874.413863</td>\n","      <td>root_mean_squared_error</td>\n","      <td>13.238459</td>\n","      <td>213.579978</td>\n","      <td>13.238459</td>\n","      <td>213.579978</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>RandomForest_r195_BAG_L1</td>\n","      <td>-77292.027794</td>\n","      <td>root_mean_squared_error</td>\n","      <td>16.845897</td>\n","      <td>351.529874</td>\n","      <td>16.845897</td>\n","      <td>351.529874</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>ExtraTreesMSE_BAG_L1</td>\n","      <td>-77344.072883</td>\n","      <td>root_mean_squared_error</td>\n","      <td>12.943583</td>\n","      <td>267.960581</td>\n","      <td>12.943583</td>\n","      <td>267.960581</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>RandomForestMSE_BAG_L1</td>\n","      <td>-78153.007850</td>\n","      <td>root_mean_squared_error</td>\n","      <td>13.228894</td>\n","      <td>365.255172</td>\n","      <td>13.228894</td>\n","      <td>365.255172</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>NeuralNetTorch_r30_BAG_L1</td>\n","      <td>-80079.180242</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1.652692</td>\n","      <td>1362.589340</td>\n","      <td>1.652692</td>\n","      <td>1362.589340</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>26</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>NeuralNetTorch_r22_BAG_L1</td>\n","      <td>-90209.188547</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1.351551</td>\n","      <td>658.290344</td>\n","      <td>1.351551</td>\n","      <td>658.290344</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>NeuralNetTorch_r86_BAG_L1</td>\n","      <td>-90209.558475</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1.366541</td>\n","      <td>609.403784</td>\n","      <td>1.366541</td>\n","      <td>609.403784</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>NeuralNetTorch_r22_BAG_L2</td>\n","      <td>-90921.513627</td>\n","      <td>root_mean_squared_error</td>\n","      <td>131.704071</td>\n","      <td>17989.742940</td>\n","      <td>3.215448</td>\n","      <td>135.796602</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>51</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                          model     score_val              eval_metric  \\\n","0           WeightedEnsemble_L3 -72488.637193  root_mean_squared_error   \n","1               CatBoost_BAG_L2 -72534.730387  root_mean_squared_error   \n","2           WeightedEnsemble_L2 -72552.964827  root_mean_squared_error   \n","3          CatBoost_r177_BAG_L2 -72564.952583  root_mean_squared_error   \n","4           LightGBM_r96_BAG_L2 -72598.539278  root_mean_squared_error   \n","5             LightGBMXT_BAG_L2 -72661.834380  root_mean_squared_error   \n","6           CatBoost_r13_BAG_L1 -72766.972850  root_mean_squared_error   \n","7            CatBoost_r9_BAG_L1 -72805.334784  root_mean_squared_error   \n","8               CatBoost_BAG_L1 -72812.796073  root_mean_squared_error   \n","9           CatBoost_r50_BAG_L1 -72822.085879  root_mean_squared_error   \n","10         CatBoost_r177_BAG_L1 -72844.316077  root_mean_squared_error   \n","11         CatBoost_r137_BAG_L1 -72844.496294  root_mean_squared_error   \n","12       NeuralNetFastAI_BAG_L2 -72864.238026  root_mean_squared_error   \n","13          LightGBM_r96_BAG_L1 -72867.276922  root_mean_squared_error   \n","14            LightGBMXT_BAG_L1 -72917.481425  root_mean_squared_error   \n","15           CatBoost_r9_BAG_L2 -72933.404539  root_mean_squared_error   \n","16         LightGBM_r131_BAG_L2 -72981.744018  root_mean_squared_error   \n","17         LightGBM_r130_BAG_L1 -72991.827008  root_mean_squared_error   \n","18               XGBoost_BAG_L2 -73009.771517  root_mean_squared_error   \n","19        NeuralNetTorch_BAG_L2 -73012.369189  root_mean_squared_error   \n","20         LightGBM_r188_BAG_L1 -73025.414165  root_mean_squared_error   \n","21              LightGBM_BAG_L2 -73054.033238  root_mean_squared_error   \n","22    NeuralNetTorch_r79_BAG_L2 -73077.282358  root_mean_squared_error   \n","23         LightGBM_r131_BAG_L1 -73119.010616  root_mean_squared_error   \n","24  NeuralNetFastAI_r145_BAG_L1 -73166.785583  root_mean_squared_error   \n","25       NeuralNetFastAI_BAG_L1 -73204.822678  root_mean_squared_error   \n","26              LightGBM_BAG_L1 -73211.006130  root_mean_squared_error   \n","27  NeuralNetFastAI_r191_BAG_L1 -73230.812248  root_mean_squared_error   \n","28           XGBoost_r89_BAG_L1 -73256.835521  root_mean_squared_error   \n","29  NeuralNetFastAI_r102_BAG_L1 -73304.278592  root_mean_squared_error   \n","30       ExtraTrees_r172_BAG_L1 -73338.917482  root_mean_squared_error   \n","31  NeuralNetFastAI_r191_BAG_L2 -73401.062963  root_mean_squared_error   \n","32        NeuralNetTorch_BAG_L1 -73419.679730  root_mean_squared_error   \n","33    NeuralNetTorch_r79_BAG_L1 -73457.894931  root_mean_squared_error   \n","34         LightGBMLarge_BAG_L2 -73470.109311  root_mean_squared_error   \n","35         LightGBMLarge_BAG_L1 -73620.198965  root_mean_squared_error   \n","36   NeuralNetFastAI_r11_BAG_L1 -73634.830372  root_mean_squared_error   \n","37               XGBoost_BAG_L1 -73649.378532  root_mean_squared_error   \n","38           XGBoost_r33_BAG_L1 -73705.454232  root_mean_squared_error   \n","39  NeuralNetFastAI_r103_BAG_L1 -73760.151896  root_mean_squared_error   \n","40         ExtraTreesMSE_BAG_L2 -73921.660451  root_mean_squared_error   \n","41          XGBoost_r194_BAG_L1 -74016.457249  root_mean_squared_error   \n","42          CatBoost_r69_BAG_L1 -74103.980294  root_mean_squared_error   \n","43       RandomForestMSE_BAG_L2 -74570.856246  root_mean_squared_error   \n","44        ExtraTrees_r42_BAG_L1 -76874.413863  root_mean_squared_error   \n","45     RandomForest_r195_BAG_L1 -77292.027794  root_mean_squared_error   \n","46         ExtraTreesMSE_BAG_L1 -77344.072883  root_mean_squared_error   \n","47       RandomForestMSE_BAG_L1 -78153.007850  root_mean_squared_error   \n","48    NeuralNetTorch_r30_BAG_L1 -80079.180242  root_mean_squared_error   \n","49    NeuralNetTorch_r22_BAG_L1 -90209.188547  root_mean_squared_error   \n","50    NeuralNetTorch_r86_BAG_L1 -90209.558475  root_mean_squared_error   \n","51    NeuralNetTorch_r22_BAG_L2 -90921.513627  root_mean_squared_error   \n","\n","    pred_time_val      fit_time  pred_time_val_marginal  fit_time_marginal  \\\n","0      156.222369  21327.878922                0.003391           0.756852   \n","1      129.351318  17945.003625                0.862696          91.057286   \n","2       38.508065   9617.831020                0.004266           1.009948   \n","3      129.170103  17931.880231                0.681480          77.933892   \n","4      129.589986  17957.948561                1.101363         104.002222   \n","5      129.009820  17932.420630                0.521198          78.474292   \n","6        3.816768    314.805590                3.816768         314.805590   \n","7        0.960838     84.314971                0.960838          84.314971   \n","8        1.411836    132.196657                1.411836         132.196657   \n","9        0.783241     65.064961                0.783241          65.064961   \n","10       1.037409     97.259647                1.037409          97.259647   \n","11       1.446389    137.021951                1.446389         137.021951   \n","12     132.801277  19709.289176                4.312655        1855.342837   \n","13       2.990662    112.915504                2.990662         112.915504   \n","14       0.790484     64.146789                0.790484          64.146789   \n","15     129.269627  17917.064875                0.781004          63.118537   \n","16     129.557734  17971.214538                1.069111         117.268199   \n","17       0.605696     66.568236                0.605696          66.568236   \n","18     130.255580  17913.612977                1.766957          59.666638   \n","19     131.708359  18799.421771                3.219737         945.475432   \n","20       1.062339     77.245158                1.062339          77.245158   \n","21     128.958337  17928.333816                0.469715          74.387477   \n","22     131.834625  18785.099875                3.346003         931.153536   \n","23       1.535072    100.106019                1.535072         100.106019   \n","24       7.947071   3694.630528                7.947071        3694.630528   \n","25       4.113538   1776.686076                4.113538        1776.686076   \n","26       0.467164     59.917255                0.467164          59.917255   \n","27       4.120958   1898.687822                4.120958        1898.687822   \n","28       1.252681     48.291197                1.252681          48.291197   \n","29       1.024712    329.587118                1.024712         329.587118   \n","30      13.637557    284.051960               13.637557         284.051960   \n","31     132.870752  19123.225087                4.382129        1269.278749   \n","32       1.336806   1457.581299                1.336806        1457.581299   \n","33       1.493420   1102.423810                1.493420        1102.423810   \n","34     129.192133  17951.556773                0.703511          97.610435   \n","35       0.644322     71.662214                0.644322          71.662214   \n","36       7.607835   1706.814909                7.607835        1706.814909   \n","37       1.171746     47.108245                1.171746          47.108245   \n","38       1.420637     65.421180                1.420637          65.421180   \n","39       4.147008    134.938038                4.147008         134.938038   \n","40     146.722529  18331.244292               18.233906         477.297953   \n","41       0.639613     45.868675                0.639613          45.868675   \n","42       0.395204     50.021456                0.395204          50.021456   \n","43     149.627795  20317.326983               21.139173        2463.380644   \n","44      13.238459    213.579978               13.238459         213.579978   \n","45      16.845897    351.529874               16.845897         351.529874   \n","46      12.943583    267.960581               12.943583         267.960581   \n","47      13.228894    365.255172               13.228894         365.255172   \n","48       1.652692   1362.589340                1.652692        1362.589340   \n","49       1.351551    658.290344                1.351551         658.290344   \n","50       1.366541    609.403784                1.366541         609.403784   \n","51     131.704071  17989.742940                3.215448         135.796602   \n","\n","    stack_level  can_infer  fit_order  \n","0             3       True         52  \n","1             2       True         39  \n","2             2       True         35  \n","3             2       True         45  \n","4             2       True         50  \n","5             2       True         36  \n","6             1       True         21  \n","7             1       True         14  \n","8             1       True          4  \n","9             1       True         29  \n","10            1       True         10  \n","11            1       True         19  \n","12            2       True         41  \n","13            1       True         15  \n","14            1       True          1  \n","15            2       True         49  \n","16            2       True         47  \n","17            1       True         27  \n","18            2       True         42  \n","19            2       True         43  \n","20            1       True         23  \n","21            2       True         37  \n","22            2       True         46  \n","23            1       True         12  \n","24            1       True         24  \n","25            1       True          6  \n","26            1       True          2  \n","27            1       True         13  \n","28            1       True         25  \n","29            1       True         20  \n","30            1       True         32  \n","31            2       True         48  \n","32            1       True          8  \n","33            1       True         11  \n","34            2       True         44  \n","35            1       True          9  \n","36            1       True         30  \n","37            1       True          7  \n","38            1       True         17  \n","39            1       True         34  \n","40            2       True         40  \n","41            1       True         31  \n","42            1       True         33  \n","43            2       True         38  \n","44            1       True         18  \n","45            1       True         22  \n","46            1       True          5  \n","47            1       True          3  \n","48            1       True         26  \n","49            1       True         16  \n","50            1       True         28  \n","51            2       True         51  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["predictor.leaderboard()"]},{"cell_type":"markdown","id":"aaa05d0a","metadata":{"papermill":{"duration":0.034264,"end_time":"2024-09-12T16:38:34.296401","exception":false,"start_time":"2024-09-12T16:38:34.262137","status":"completed"},"tags":[]},"source":["**What the Leaderboard Shows:**\n","* **Model:** The name of the model that was trained. This can include various types of models such as Random Forest, Gradient Boosting, Neural Networks, etc.\n","* **Time Training:** The time taken to train the model.\n","* **Time Prediction:** The time taken to make predictions with the model.\n","* **Score Validation:** The score (e.g., RMSE) on the validation set, indicating how well the model performs on data it hasnt seen during training.\n","* **Fit Order:** The order in which the models were trained.\n","\n","**Interpreting the Table:**\n","* **WeightedEnsemble_L2:** This is an ensemble model that combines predictions from multiple other models (e.g., LightGBM, CatBoost). It is ranked first due to its lowest RMSE on the validation set (Score_Validation).\n","* **LightGBM_BAG_L1:** A LightGBM model that was also considered. It shows slightly worse performance than the ensemble but may have taken less time to train (Training_Time)."]},{"cell_type":"markdown","id":"c5c10392","metadata":{"papermill":{"duration":0.033996,"end_time":"2024-09-12T16:38:34.366229","exception":false,"start_time":"2024-09-12T16:38:34.332233","status":"completed"},"tags":[]},"source":["# Make Predictions"]},{"cell_type":"code","execution_count":9,"id":"80b3d54a","metadata":{"execution":{"iopub.execute_input":"2024-09-12T16:38:34.500653Z","iopub.status.busy":"2024-09-12T16:38:34.50024Z","iopub.status.idle":"2024-09-12T16:45:22.812271Z","shell.execute_reply":"2024-09-12T16:45:22.810947Z"},"papermill":{"duration":408.350257,"end_time":"2024-09-12T16:45:22.814933","exception":false,"start_time":"2024-09-12T16:38:34.464676","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n"]}],"source":["test_pred = predictor.predict(test_data)"]},{"cell_type":"markdown","id":"092919b0","metadata":{"papermill":{"duration":0.040326,"end_time":"2024-09-12T16:45:22.894794","exception":false,"start_time":"2024-09-12T16:45:22.854468","status":"completed"},"tags":[]},"source":["# Submission"]},{"cell_type":"code","execution_count":10,"id":"86bb5fe1","metadata":{"execution":{"iopub.execute_input":"2024-09-12T16:45:22.972614Z","iopub.status.busy":"2024-09-12T16:45:22.97132Z","iopub.status.idle":"2024-09-12T16:45:23.264743Z","shell.execute_reply":"2024-09-12T16:45:23.263712Z"},"papermill":{"duration":0.335541,"end_time":"2024-09-12T16:45:23.267544","exception":false,"start_time":"2024-09-12T16:45:22.932003","status":"completed"},"tags":[]},"outputs":[],"source":["submission['price'] = test_pred\n","submission.to_csv('submission.csv', index=False)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":9057646,"sourceId":76728,"sourceType":"competition"}],"dockerImageVersionId":30761,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"papermill":{"default_parameters":{},"duration":36522.110427,"end_time":"2024-09-12T16:45:28.632746","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-09-12T06:36:46.522319","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}