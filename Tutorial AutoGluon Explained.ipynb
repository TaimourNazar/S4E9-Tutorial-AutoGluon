{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/taimour/s4e9-tutorial-autogluon-explained?scriptVersionId=196489470\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"e2ed8715","metadata":{"papermill":{"duration":0.006436,"end_time":"2024-09-13T10:41:22.916249","exception":false,"start_time":"2024-09-13T10:41:22.909813","status":"completed"},"tags":[]},"source":["# Tutorial - AutoGluon Explained\n","![](https://auto.gluon.ai/stable/_static/autogluon.png)"]},{"cell_type":"markdown","id":"80b9a4fd","metadata":{"papermill":{"duration":0.005349,"end_time":"2024-09-13T10:41:22.927272","exception":false,"start_time":"2024-09-13T10:41:22.921923","status":"completed"},"tags":[]},"source":["# Installation\n","\n","To keep notebook clean and avoid alot of installation text in notebook, lets use subprocess"]},{"cell_type":"code","execution_count":1,"id":"f5f50e7b","metadata":{"execution":{"iopub.execute_input":"2024-09-13T10:41:22.940058Z","iopub.status.busy":"2024-09-13T10:41:22.93976Z","iopub.status.idle":"2024-09-13T10:42:30.368496Z","shell.execute_reply":"2024-09-13T10:42:30.367655Z"},"papermill":{"duration":67.443944,"end_time":"2024-09-13T10:42:30.377242","exception":false,"start_time":"2024-09-13T10:41:22.933298","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["CompletedProcess(args=['pip', 'install', '-U', 'ipywidgets'], returncode=0, stdout=b'Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.1)\\nCollecting ipywidgets\\n  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\\nRequirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\\nRequirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.21.0)\\nRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\\nCollecting widgetsnbextension~=4.0.12 (from ipywidgets)\\n  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\\nCollecting jupyterlab-widgets~=3.0.12 (from ipywidgets)\\n  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\\nRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.47)\\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.0)\\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\\nDownloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\\n\\x1b[?25l   \\x1b[90m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m \\x1b[32m0.0/139.8 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m\\r\\x1b[2K   \\x1b[91m\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m\\x1b[91m\\xe2\\x95\\xb8\\x1b[0m\\x1b[90m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m \\x1b[32m10.2/139.8 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m\\r\\x1b[2K   \\x1b[91m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m\\x1b[90m\\xe2\\x95\\xba\\x1b[0m\\x1b[90m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m \\x1b[32m81.9/139.8 kB\\x1b[0m \\x1b[31m1.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m\\r\\x1b[2K   \\x1b[90m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m \\x1b[32m139.8/139.8 kB\\x1b[0m \\x1b[31m1.5 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m\\n\\x1b[?25hDownloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\\n\\x1b[?25l   \\x1b[90m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m \\x1b[32m0.0/214.4 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m\\r\\x1b[2K   \\x1b[91m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m\\x1b[90m\\xe2\\x95\\xba\\x1b[0m\\x1b[90m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m \\x1b[32m174.1/214.4 kB\\x1b[0m \\x1b[31m11.1 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m\\r\\x1b[2K   \\x1b[90m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m \\x1b[32m214.4/214.4 kB\\x1b[0m \\x1b[31m4.4 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m\\n\\x1b[?25hDownloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\\n\\x1b[?25l   \\x1b[90m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m \\x1b[32m0.0/2.3 MB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m\\r\\x1b[2K   \\x1b[91m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m\\x1b[90m\\xe2\\x95\\xba\\x1b[0m\\x1b[90m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m \\x1b[32m0.4/2.3 MB\\x1b[0m \\x1b[31m25.3 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m\\r\\x1b[2K   \\x1b[91m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m\\x1b[90m\\xe2\\x95\\xba\\x1b[0m\\x1b[90m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m \\x1b[32m1.2/2.3 MB\\x1b[0m \\x1b[31m20.2 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m\\r\\x1b[2K   \\x1b[91m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m\\x1b[91m\\xe2\\x95\\xb8\\x1b[0m \\x1b[32m2.3/2.3 MB\\x1b[0m \\x1b[31m25.5 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m\\r\\x1b[2K   \\x1b[90m\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\xe2\\x94\\x81\\x1b[0m \\x1b[32m2.3/2.3 MB\\x1b[0m \\x1b[31m21.1 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m\\n\\x1b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\\n  Attempting uninstall: widgetsnbextension\\n    Found existing installation: widgetsnbextension 3.6.8\\n    Uninstalling widgetsnbextension-3.6.8:\\n      Successfully uninstalled widgetsnbextension-3.6.8\\n  Attempting uninstall: jupyterlab-widgets\\n    Found existing installation: jupyterlab_widgets 3.0.11\\n    Uninstalling jupyterlab_widgets-3.0.11:\\n      Successfully uninstalled jupyterlab_widgets-3.0.11\\n  Attempting uninstall: ipywidgets\\n    Found existing installation: ipywidgets 7.7.1\\n    Uninstalling ipywidgets-7.7.1:\\n      Successfully uninstalled ipywidgets-7.7.1\\nSuccessfully installed ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\\n', stderr=b\"\\x1b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\\nbigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\\nbigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\\nbigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.2 which is incompatible.\\ndataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.8.2 which is incompatible.\\x1b[0m\\x1b[31m\\n\\x1b[0m\")"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import subprocess\n","\n","subprocess.run([\"pip\", \"install\", \"ray==2.10.0\"], capture_output=True)\n","subprocess.run([\"pip\", \"install\", \"autogluon.tabular\"], capture_output=True)\n","subprocess.run([\"pip\", \"install\", \"-U\", \"ipywidgets\"], capture_output=True)"]},{"cell_type":"markdown","id":"a96be49b","metadata":{"papermill":{"duration":0.005544,"end_time":"2024-09-13T10:42:30.388697","exception":false,"start_time":"2024-09-13T10:42:30.383153","status":"completed"},"tags":[]},"source":["# Import"]},{"cell_type":"code","execution_count":2,"id":"12f0931a","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-13T10:42:30.401417Z","iopub.status.busy":"2024-09-13T10:42:30.401127Z","iopub.status.idle":"2024-09-13T10:42:32.643242Z","shell.execute_reply":"2024-09-13T10:42:32.642306Z"},"papermill":{"duration":2.251276,"end_time":"2024-09-13T10:42:32.645754","exception":false,"start_time":"2024-09-13T10:42:30.394478","status":"completed"},"tags":[]},"outputs":[],"source":["import pandas as pd\n","from autogluon.tabular import TabularDataset, TabularPredictor"]},{"cell_type":"markdown","id":"33358415","metadata":{"papermill":{"duration":0.005758,"end_time":"2024-09-13T10:42:32.657645","exception":false,"start_time":"2024-09-13T10:42:32.651887","status":"completed"},"tags":[]},"source":["# Read Data"]},{"cell_type":"code","execution_count":3,"id":"4ba4ec3d","metadata":{"execution":{"iopub.execute_input":"2024-09-13T10:42:32.670741Z","iopub.status.busy":"2024-09-13T10:42:32.67025Z","iopub.status.idle":"2024-09-13T10:42:34.096743Z","shell.execute_reply":"2024-09-13T10:42:34.095775Z"},"papermill":{"duration":1.43559,"end_time":"2024-09-13T10:42:34.099127","exception":false,"start_time":"2024-09-13T10:42:32.663537","status":"completed"},"tags":[]},"outputs":[],"source":["train_data = pd.read_csv('/kaggle/input/playground-series-s4e9/train.csv').drop('id', axis=1)\n","test_data = pd.read_csv('/kaggle/input/playground-series-s4e9/test.csv').drop('id', axis=1)\n","submission = pd.read_csv('/kaggle/input/playground-series-s4e9/sample_submission.csv')"]},{"cell_type":"markdown","id":"8ad26a0b","metadata":{"papermill":{"duration":0.005818,"end_time":"2024-09-13T10:42:34.111187","exception":false,"start_time":"2024-09-13T10:42:34.105369","status":"completed"},"tags":[]},"source":["# View Training and Test data"]},{"cell_type":"code","execution_count":4,"id":"16f1441d","metadata":{"execution":{"iopub.execute_input":"2024-09-13T10:42:34.124387Z","iopub.status.busy":"2024-09-13T10:42:34.12368Z","iopub.status.idle":"2024-09-13T10:42:34.140929Z","shell.execute_reply":"2024-09-13T10:42:34.140116Z"},"papermill":{"duration":0.026056,"end_time":"2024-09-13T10:42:34.143025","exception":false,"start_time":"2024-09-13T10:42:34.116969","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>brand</th>\n","      <th>model</th>\n","      <th>model_year</th>\n","      <th>milage</th>\n","      <th>fuel_type</th>\n","      <th>engine</th>\n","      <th>transmission</th>\n","      <th>ext_col</th>\n","      <th>int_col</th>\n","      <th>accident</th>\n","      <th>clean_title</th>\n","      <th>price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>MINI</td>\n","      <td>Cooper S Base</td>\n","      <td>2007</td>\n","      <td>213000</td>\n","      <td>Gasoline</td>\n","      <td>172.0HP 1.6L 4 Cylinder Engine Gasoline Fuel</td>\n","      <td>A/T</td>\n","      <td>Yellow</td>\n","      <td>Gray</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","      <td>4200</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Lincoln</td>\n","      <td>LS V8</td>\n","      <td>2002</td>\n","      <td>143250</td>\n","      <td>Gasoline</td>\n","      <td>252.0HP 3.9L 8 Cylinder Engine Gasoline Fuel</td>\n","      <td>A/T</td>\n","      <td>Silver</td>\n","      <td>Beige</td>\n","      <td>At least 1 accident or damage reported</td>\n","      <td>Yes</td>\n","      <td>4999</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Chevrolet</td>\n","      <td>Silverado 2500 LT</td>\n","      <td>2002</td>\n","      <td>136731</td>\n","      <td>E85 Flex Fuel</td>\n","      <td>320.0HP 5.3L 8 Cylinder Engine Flex Fuel Capab...</td>\n","      <td>A/T</td>\n","      <td>Blue</td>\n","      <td>Gray</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","      <td>13900</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Genesis</td>\n","      <td>G90 5.0 Ultimate</td>\n","      <td>2017</td>\n","      <td>19500</td>\n","      <td>Gasoline</td>\n","      <td>420.0HP 5.0L 8 Cylinder Engine Gasoline Fuel</td>\n","      <td>Transmission w/Dual Shift Mode</td>\n","      <td>Black</td>\n","      <td>Black</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","      <td>45000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Mercedes-Benz</td>\n","      <td>Metris Base</td>\n","      <td>2021</td>\n","      <td>7388</td>\n","      <td>Gasoline</td>\n","      <td>208.0HP 2.0L 4 Cylinder Engine Gasoline Fuel</td>\n","      <td>7-Speed A/T</td>\n","      <td>Black</td>\n","      <td>Beige</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","      <td>97500</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           brand              model  model_year  milage      fuel_type  \\\n","0           MINI      Cooper S Base        2007  213000       Gasoline   \n","1        Lincoln              LS V8        2002  143250       Gasoline   \n","2      Chevrolet  Silverado 2500 LT        2002  136731  E85 Flex Fuel   \n","3        Genesis   G90 5.0 Ultimate        2017   19500       Gasoline   \n","4  Mercedes-Benz        Metris Base        2021    7388       Gasoline   \n","\n","                                              engine  \\\n","0       172.0HP 1.6L 4 Cylinder Engine Gasoline Fuel   \n","1       252.0HP 3.9L 8 Cylinder Engine Gasoline Fuel   \n","2  320.0HP 5.3L 8 Cylinder Engine Flex Fuel Capab...   \n","3       420.0HP 5.0L 8 Cylinder Engine Gasoline Fuel   \n","4       208.0HP 2.0L 4 Cylinder Engine Gasoline Fuel   \n","\n","                     transmission ext_col int_col  \\\n","0                             A/T  Yellow    Gray   \n","1                             A/T  Silver   Beige   \n","2                             A/T    Blue    Gray   \n","3  Transmission w/Dual Shift Mode   Black   Black   \n","4                     7-Speed A/T   Black   Beige   \n","\n","                                 accident clean_title  price  \n","0                           None reported         Yes   4200  \n","1  At least 1 accident or damage reported         Yes   4999  \n","2                           None reported         Yes  13900  \n","3                           None reported         Yes  45000  \n","4                           None reported         Yes  97500  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["train_data.head()"]},{"cell_type":"code","execution_count":5,"id":"5d45c079","metadata":{"execution":{"iopub.execute_input":"2024-09-13T10:42:34.157499Z","iopub.status.busy":"2024-09-13T10:42:34.157214Z","iopub.status.idle":"2024-09-13T10:42:34.170784Z","shell.execute_reply":"2024-09-13T10:42:34.16998Z"},"papermill":{"duration":0.022906,"end_time":"2024-09-13T10:42:34.172651","exception":false,"start_time":"2024-09-13T10:42:34.149745","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>brand</th>\n","      <th>model</th>\n","      <th>model_year</th>\n","      <th>milage</th>\n","      <th>fuel_type</th>\n","      <th>engine</th>\n","      <th>transmission</th>\n","      <th>ext_col</th>\n","      <th>int_col</th>\n","      <th>accident</th>\n","      <th>clean_title</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Land</td>\n","      <td>Rover LR2 Base</td>\n","      <td>2015</td>\n","      <td>98000</td>\n","      <td>Gasoline</td>\n","      <td>240.0HP 2.0L 4 Cylinder Engine Gasoline Fuel</td>\n","      <td>6-Speed A/T</td>\n","      <td>White</td>\n","      <td>Beige</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Land</td>\n","      <td>Rover Defender SE</td>\n","      <td>2020</td>\n","      <td>9142</td>\n","      <td>Hybrid</td>\n","      <td>395.0HP 3.0L Straight 6 Cylinder Engine Gasoli...</td>\n","      <td>8-Speed A/T</td>\n","      <td>Silver</td>\n","      <td>Black</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Ford</td>\n","      <td>Expedition Limited</td>\n","      <td>2022</td>\n","      <td>28121</td>\n","      <td>Gasoline</td>\n","      <td>3.5L V6 24V PDI DOHC Twin Turbo</td>\n","      <td>10-Speed Automatic</td>\n","      <td>White</td>\n","      <td>Ebony</td>\n","      <td>None reported</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Audi</td>\n","      <td>A6 2.0T Sport</td>\n","      <td>2016</td>\n","      <td>61258</td>\n","      <td>Gasoline</td>\n","      <td>2.0 Liter TFSI</td>\n","      <td>Automatic</td>\n","      <td>Silician Yellow</td>\n","      <td>Black</td>\n","      <td>None reported</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Audi</td>\n","      <td>A6 2.0T Premium Plus</td>\n","      <td>2018</td>\n","      <td>59000</td>\n","      <td>Gasoline</td>\n","      <td>252.0HP 2.0L 4 Cylinder Engine Gasoline Fuel</td>\n","      <td>A/T</td>\n","      <td>Gray</td>\n","      <td>Black</td>\n","      <td>None reported</td>\n","      <td>Yes</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  brand                 model  model_year  milage fuel_type  \\\n","0  Land        Rover LR2 Base        2015   98000  Gasoline   \n","1  Land     Rover Defender SE        2020    9142    Hybrid   \n","2  Ford    Expedition Limited        2022   28121  Gasoline   \n","3  Audi         A6 2.0T Sport        2016   61258  Gasoline   \n","4  Audi  A6 2.0T Premium Plus        2018   59000  Gasoline   \n","\n","                                              engine        transmission  \\\n","0       240.0HP 2.0L 4 Cylinder Engine Gasoline Fuel         6-Speed A/T   \n","1  395.0HP 3.0L Straight 6 Cylinder Engine Gasoli...         8-Speed A/T   \n","2                    3.5L V6 24V PDI DOHC Twin Turbo  10-Speed Automatic   \n","3                                     2.0 Liter TFSI           Automatic   \n","4       252.0HP 2.0L 4 Cylinder Engine Gasoline Fuel                 A/T   \n","\n","           ext_col int_col       accident clean_title  \n","0            White   Beige  None reported         Yes  \n","1           Silver   Black  None reported         Yes  \n","2            White   Ebony  None reported         NaN  \n","3  Silician Yellow   Black  None reported         NaN  \n","4             Gray   Black  None reported         Yes  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["test_data.head()"]},{"cell_type":"markdown","id":"b3dd031f","metadata":{"papermill":{"duration":0.006668,"end_time":"2024-09-13T10:42:34.185941","exception":false,"start_time":"2024-09-13T10:42:34.179273","status":"completed"},"tags":[]},"source":["# AutoGluon Introduction\n","\n","AutoGluon is an open-source AutoML framework developed by Amazon that simplifies the process of building machine learning models for various tasks, including tabular data prediction, image classification, text analysis, and more. It automates the entire machine learning pipeline, from data preprocessing to model selection and hyperparameter tuning, making it accessible for users with minimal coding and machine learning expertise. AutoGluon supports both classification and regression problems and leverages powerful ensemble techniques to deliver high-quality models. It also allows users to specify resource constraints, like time limits and hardware availability (GPUs/CPUs), to optimize model training efficiency."]},{"cell_type":"markdown","id":"dc91c03f","metadata":{"papermill":{"duration":0.006233,"end_time":"2024-09-13T10:42:34.198584","exception":false,"start_time":"2024-09-13T10:42:34.192351","status":"completed"},"tags":[]},"source":["# AutoGluon Code with Explanation"]},{"cell_type":"code","execution_count":6,"id":"bf7feaf2","metadata":{"execution":{"iopub.execute_input":"2024-09-13T10:42:34.213144Z","iopub.status.busy":"2024-09-13T10:42:34.212351Z","iopub.status.idle":"2024-09-13T12:42:49.604298Z","shell.execute_reply":"2024-09-13T12:42:49.603162Z"},"papermill":{"duration":7215.403031,"end_time":"2024-09-13T12:42:49.608042","exception":false,"start_time":"2024-09-13T10:42:34.205011","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["No path specified. Models will be saved in: \"AutogluonModels/ag-20240913_104234\"\n","2024-09-13 10:42:37,272\tINFO worker.py:1752 -- Started a local Ray instance.\n","\u001b[36m(_ray_fit pid=453)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=453)\u001b[0m [LightGBM] [Fatal] bin size 1669 cannot run on GPU\n","\u001b[36m(_ray_fit pid=453)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=495)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=495)\u001b[0m [LightGBM] [Fatal] bin size 1665 cannot run on GPU\n","\u001b[36m(_ray_fit pid=495)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=537)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=537)\u001b[0m [LightGBM] [Fatal] bin size 1670 cannot run on GPU\n","\u001b[36m(_ray_fit pid=537)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=579)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=579)\u001b[0m [LightGBM] [Fatal] bin size 1666 cannot run on GPU\n","\u001b[36m(_ray_fit pid=579)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=621)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=621)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=621)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=663)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=663)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=663)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=705)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=705)\u001b[0m [LightGBM] [Fatal] bin size 1664 cannot run on GPU\n","\u001b[36m(_ray_fit pid=705)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=747)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=747)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n","\u001b[36m(_ray_fit pid=747)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=879)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=879)\u001b[0m [LightGBM] [Fatal] bin size 1669 cannot run on GPU\n","\u001b[36m(_ray_fit pid=879)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=921)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=921)\u001b[0m [LightGBM] [Fatal] bin size 1665 cannot run on GPU\n","\u001b[36m(_ray_fit pid=921)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=963)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=963)\u001b[0m [LightGBM] [Fatal] bin size 1670 cannot run on GPU\n","\u001b[36m(_ray_fit pid=963)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=1005)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1005)\u001b[0m [LightGBM] [Fatal] bin size 1666 cannot run on GPU\n","\u001b[36m(_ray_fit pid=1005)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=1047)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1047)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=1047)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=1089)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1089)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=1089)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=1131)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1131)\u001b[0m [LightGBM] [Fatal] bin size 1664 cannot run on GPU\n","\u001b[36m(_ray_fit pid=1131)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=1173)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1173)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n","\u001b[36m(_ray_fit pid=1173)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=1319)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1319)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=1395)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1395)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=1471)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1471)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=1547)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1547)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=1623)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1623)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=1699)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1699)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=1775)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1775)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=1851)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=1851)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n","\u001b[36m(_ray_fit pid=2031)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 6)\n","\u001b[36m(_ray_fit pid=2031)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2031)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=2084)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2084)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=2137)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2137)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=2190)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 6)\n","\u001b[36m(_ray_fit pid=2190)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2190)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=2243)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2243)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=2243)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 6)\n","\u001b[36m(_ray_fit pid=2296)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 6)\n","\u001b[36m(_ray_fit pid=2296)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2296)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=2349)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2349)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=2349)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 6)\n","\u001b[36m(_ray_fit pid=2402)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 6)\n","\u001b[36m(_ray_fit pid=2402)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2402)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n","\u001b[36m(_ray_fit pid=2545)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:00:47] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=2545)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=2545)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:00:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=2545)\u001b[0m \n","\u001b[36m(_ray_fit pid=2545)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=2545)\u001b[0m \n","\u001b[36m(_ray_fit pid=2545)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=2545)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:00:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=2545)\u001b[0m \n","\u001b[36m(_ray_fit pid=2545)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=2545)\u001b[0m \n","\u001b[36m(_ray_fit pid=2545)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=2545)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:00:48] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=2545)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=2545)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=2545)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=2545)\u001b[0m \n","\u001b[36m(_ray_fit pid=2545)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=2545)\u001b[0m \n","\u001b[36m(_ray_fit pid=2545)\u001b[0m   warnings.warn(smsg, UserWarning)\n","\u001b[36m(_ray_fit pid=2588)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:00:52] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=2588)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n","\u001b[36m(_ray_fit pid=2588)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:00:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=2588)\u001b[0m \u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2588)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=2588)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:00:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=2588)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=2588)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:00:53] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=2588)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=2588)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=2588)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=2588)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=2632)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:00:57] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=2632)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2632)\u001b[0m \u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2632)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:00:58] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=2632)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=2632)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=2632)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=2632)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=2632)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:00:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2632)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2675)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:01:02] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=2675)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2675)\u001b[0m \u001b[32m [repeated 10x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2675)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:01:03] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=2675)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=2675)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=2675)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=2675)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=2675)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:01:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2675)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2718)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:01:07] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=2718)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2718)\u001b[0m \u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2718)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:01:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2718)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2718)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:01:08] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=2718)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=2718)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=2718)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=2718)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=2762)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:01:13] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=2762)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 5x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2762)\u001b[0m \u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2762)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:01:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2762)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2762)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:01:13] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=2762)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=2762)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=2762)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=2762)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=2806)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:01:18] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=2806)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:01:18] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=2806)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=2806)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=2806)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=2806)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=2849)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 6x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2849)\u001b[0m \u001b[32m [repeated 8x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2849)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:01:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2849)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\u001b[32m [repeated 3x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2849)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:01:23] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n","\u001b[36m(_ray_fit pid=2849)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:01:23] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n","\u001b[36m(_ray_fit pid=2849)\u001b[0m Potential solutions:\n","\u001b[36m(_ray_fit pid=2849)\u001b[0m - Use a data structure that matches the device ordinal in the booster.\n","\u001b[36m(_ray_fit pid=2849)\u001b[0m - Set the device for booster before call to inplace_predict.\n","\u001b[36m(_ray_fit pid=2849)\u001b[0m This warning will only be shown once.\n","\u001b[36m(_ray_fit pid=2982)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=2849)\u001b[0m   warnings.warn(smsg, UserWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2849)\u001b[0m \u001b[32m [repeated 4x across cluster]\u001b[0m\n","\u001b[36m(_ray_fit pid=2849)\u001b[0m /opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [11:01:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n","\u001b[36m(_ray_fit pid=2849)\u001b[0m     E.g. tree_method = \"hist\", device = \"cuda\"\n","\u001b[36m(_ray_fit pid=2982)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 2)\n","\u001b[36m(_ray_fit pid=2982)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=2982)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=3030)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=3030)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 2)\n","\u001b[36m(_ray_fit pid=3030)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=3030)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=3077)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=3077)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 2)\n","\u001b[36m(_ray_fit pid=3077)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=3077)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=3124)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=3124)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 2)\n","\u001b[36m(_ray_fit pid=3124)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=3124)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=3171)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=3171)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 2)\n","\u001b[36m(_ray_fit pid=3171)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=3171)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=3218)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=3218)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 2)\n","\u001b[36m(_ray_fit pid=3218)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=3218)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=3265)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=3265)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 2)\n","\u001b[36m(_ray_fit pid=3265)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=3265)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=3312)\u001b[0m TabularNeuralNetTorchModel not yet able to use more than 1 GPU. 'num_gpus' is set to >1, but we will be using only 1 GPU.\n","\u001b[36m(_ray_fit pid=3312)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 2)\n","\u001b[36m(_ray_fit pid=3312)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_ray_fit pid=3312)\u001b[0m   self.model = torch.load(net_filename)\n","\u001b[36m(_ray_fit pid=3455)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3455)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3455)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3497)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3497)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3497)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3539)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3539)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3539)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3581)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3581)\u001b[0m [LightGBM] [Fatal] bin size 1666 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3581)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3623)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3623)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3623)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3665)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3665)\u001b[0m [LightGBM] [Fatal] bin size 1670 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3665)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3707)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3707)\u001b[0m [LightGBM] [Fatal] bin size 1665 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3707)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3749)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3749)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3749)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3887)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3887)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3887)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3929)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3929)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3929)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=3971)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=3971)\u001b[0m [LightGBM] [Fatal] bin size 1668 cannot run on GPU\n","\u001b[36m(_ray_fit pid=3971)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=4013)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4013)\u001b[0m [LightGBM] [Fatal] bin size 1666 cannot run on GPU\n","\u001b[36m(_ray_fit pid=4013)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=4055)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4055)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=4055)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=4097)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4097)\u001b[0m [LightGBM] [Fatal] bin size 1670 cannot run on GPU\n","\u001b[36m(_ray_fit pid=4097)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=4139)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4139)\u001b[0m [LightGBM] [Fatal] bin size 1665 cannot run on GPU\n","\u001b[36m(_ray_fit pid=4139)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_ray_fit pid=4181)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n","\u001b[36m(_ray_fit pid=4181)\u001b[0m [LightGBM] [Fatal] bin size 1667 cannot run on GPU\n","\u001b[36m(_ray_fit pid=4181)\u001b[0m Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n","\u001b[36m(_dystack pid=186)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=186)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=186)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=186)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=186)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=186)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=186)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=186)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=186)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=186)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=186)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=186)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=186)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=186)\u001b[0m   return torch.load(io.BytesIO(b))\n","\u001b[36m(_dystack pid=186)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","\u001b[36m(_dystack pid=186)\u001b[0m   return torch.load(io.BytesIO(b))\n"]}],"source":["predictor = TabularPredictor(\n","    label='price',             # Target column that needs to be predicted (dependent variable)\n","    eval_metric='rmse',        # Evaluation metric (Root Mean Squared Error) used to judge the models performance\n","    problem_type='regression'  # Specifying this is a regression problem\n",").fit(\n","    train_data,                  # The training dataset containing features and the target (price)\n","    presets='best_quality',    # The preset configuration for optimal quality (though it may take more time)\n","    time_limit=3600*2,      # Time limit for training (2 hours = 3600 seconds/hour * 2 hours)\n","    verbosity=0,               # Level of logging information (0 is used to avoid alot of text in notebook)\n","    excluded_model_types=['KNN'], # Exclude K-Nearest Neighbors models from training\n","    ag_args_fit={\n","        'num_gpus': 2,          # Use 2 GPUs if available for model training\n","        'num_cpus': 4           # Use 4 CPUs for model training\n","    }\n",")"]},{"cell_type":"markdown","id":"6227b2d8","metadata":{"papermill":{"duration":0.016494,"end_time":"2024-09-13T12:42:49.642752","exception":false,"start_time":"2024-09-13T12:42:49.626258","status":"completed"},"tags":[]},"source":["* **label='price':** The column name 'price' is the target (dependent variable) to be predicted.\n","* **eval_metric='rmse':** The Root Mean Squared Error (RMSE) is chosen as the evaluation metric, which is common for regression tasks.\n","* **problem_type='regression':** Specifies that the task is a regression task (i.e., predicting continuous values).\n","* **train_data:** This is the DataFrame containing the training data with both features and the target (price).\n","* **presets='best_quality':** This preset prioritizes accuracy over training speed. It will try many models and techniques to ensure the highest possible quality.\n","* **time_limit=3600*2:** Limits the model training process to a maximum of 2 hours.\n","* **verbosity=0:** Specifies the verbosity level for logging. Higher values will show more details about the training process. To avoid alot of text in notebook we will use 0.\n","* **excluded_model_types=['KNN']:** K-Nearest Neighbors (KNN) models are excluded from being considered during training.\n","* **ag_args_fit:** This argument allows you to pass configuration options to the fitting process:\n","* **num_gpus=2:** The model will utilize 2 GPUs for training if available, speeding up the process for certain algorithms.\n","* **num_cpus=4:** The model will use 4 CPU cores during training."]},{"cell_type":"markdown","id":"221743b8","metadata":{"papermill":{"duration":0.016724,"end_time":"2024-09-13T12:42:49.676323","exception":false,"start_time":"2024-09-13T12:42:49.659599","status":"completed"},"tags":[]},"source":["# Why KNN models are excluded from training?\n","\n","**The exclusion of K-Nearest Neighbors (KNN) models from the training process in the given code is likely due to several reasons:**\n","\n","**Computational Cost:** KNN models can be computationally expensive for large datasets, especially when dealing with high-dimensional data. This is because they require calculating distances between each new data point and all training points, which can be time-consuming.\n","\n","**Sensitivity to Noise:** KNN models are sensitive to noise in the data. Outliers or noisy data points can significantly impact the predictions, leading to less accurate results.\n","\n","**Scalability Issues:** As the dataset size grows, KNN models can become increasingly difficult to scale. The computational complexity increases linearly with the number of training points, making it challenging to handle large datasets efficiently.\n","\n","**Interpretability:** KNN models are generally less interpretable compared to other machine learning algorithms. It can be difficult to understand how the model arrived at a particular prediction, making it harder to explain the model's behavior.\n","\n","\n","In summary, while KNN can be a simple and effective algorithm for certain problems, its drawbacks in terms of computational cost, sensitivity to noise, scalability, and interpretability make it less suitable for larger or more complex datasets. The decision to exclude KNN models from the training process in this specific case is likely based on these considerations and the desire to use more efficient and interpretable algorithms."]},{"cell_type":"code","execution_count":7,"id":"31f44cc0","metadata":{"execution":{"iopub.execute_input":"2024-09-13T12:42:49.720115Z","iopub.status.busy":"2024-09-13T12:42:49.718819Z","iopub.status.idle":"2024-09-13T12:42:50.439453Z","shell.execute_reply":"2024-09-13T12:42:50.438306Z"},"papermill":{"duration":0.744571,"end_time":"2024-09-13T12:42:50.441564","exception":false,"start_time":"2024-09-13T12:42:49.696993","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["*** Summary of fit() ***\n","Estimated performance of each model:\n","                        model     score_val              eval_metric  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n","0         WeightedEnsemble_L3 -72540.884057  root_mean_squared_error      65.730500  4965.730856                0.002595           0.507395            3       True         20\n","1             CatBoost_BAG_L2 -72573.800702  root_mean_squared_error      33.879414  3443.217167                0.404172          55.281477            2       True         16\n","2         WeightedEnsemble_L2 -72621.493206  root_mean_squared_error      30.205693  3135.454129                0.003250           0.329934            2       True         12\n","3           LightGBMXT_BAG_L2 -72715.627249  root_mean_squared_error      33.906466  3444.350420                0.431224          56.414730            2       True         13\n","4             CatBoost_BAG_L1 -72812.796073  root_mean_squared_error       1.246374   119.074448                1.246374         119.074448            1       True          4\n","5      NeuralNetFastAI_BAG_L2 -72821.524851  root_mean_squared_error      36.878074  3629.398750                3.402832         241.463060            2       True         18\n","6           LightGBMXT_BAG_L1 -72917.481425  root_mean_squared_error       0.641319    55.794910                0.641319          55.794910            1       True          1\n","7             LightGBM_BAG_L2 -73067.642474  root_mean_squared_error      33.854123  3442.930941                0.378882          54.995251            2       True         14\n","8      NeuralNetFastAI_BAG_L1 -73204.822678  root_mean_squared_error       3.426627  1470.368138                3.426627        1470.368138            1       True          6\n","9             LightGBM_BAG_L1 -73211.006130  root_mean_squared_error       0.413517    52.892165                0.413517          52.892165            1       True          2\n","10       CatBoost_r177_BAG_L1 -73226.737654  root_mean_squared_error       0.405771    45.070776                0.405771          45.070776            1       True         10\n","11             XGBoost_BAG_L2 -73405.238402  root_mean_squared_error      34.678620  3432.019403                1.203378          44.083714            2       True         19\n","12      NeuralNetTorch_BAG_L1 -73453.134631  root_mean_squared_error       1.180547   901.138193                1.180547         901.138193            1       True          8\n","13       LightGBMLarge_BAG_L1 -73620.198965  root_mean_squared_error       0.572073    60.221874                0.572073          60.221874            1       True          9\n","14             XGBoost_BAG_L1 -73649.378532  root_mean_squared_error       1.010213    41.470863                1.010213          41.470863            1       True          7\n","15       ExtraTreesMSE_BAG_L2 -74087.679922  root_mean_squared_error      46.518420  3682.227837               13.043179         294.292147            2       True         17\n","16  NeuralNetTorch_r79_BAG_L1 -74226.248751  root_mean_squared_error       1.284742   106.047982                1.284742         106.047982            1       True         11\n","17     RandomForestMSE_BAG_L2 -74677.255202  root_mean_squared_error      48.446498  4317.772048               14.971256         929.836358            2       True         15\n","18       ExtraTreesMSE_BAG_L1 -77344.072883  root_mean_squared_error      11.518689   231.008692               11.518689         231.008692            1       True          5\n","19     RandomForestMSE_BAG_L1 -78153.007850  root_mean_squared_error      11.775370   304.847648               11.775370         304.847648            1       True          3\n","Number of models trained: 20\n","Types of models trained:\n","{'StackerEnsembleModel_RF', 'StackerEnsembleModel_TabularNeuralNetTorch', 'WeightedEnsembleModel', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_NNFastAiTabular'}\n","Bagging used: True  (with 8 folds)\n","Multi-layer stack-ensembling used: True  (with 3 levels)\n","Feature Metadata (Processed):\n","(raw dtype, special dtypes):\n","('category', [])                    :  7 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n","('category', ['text_as_category'])  :  1 | ['engine']\n","('int', [])                         :  2 | ['model_year', 'milage']\n","('int', ['binned', 'text_special']) : 11 | ['engine.char_count', 'engine.word_count', 'engine.capital_ratio', 'engine.lower_ratio', 'engine.digit_ratio', ...]\n","('int', ['bool'])                   :  1 | ['clean_title']\n","('int', ['text_ngram'])             : 65 | ['__nlp__.0hp', '__nlp__.0hp 0l', '__nlp__.0hp 0l cylinder', '__nlp__.0hp 0l straight', '__nlp__.0hp 0l v6', ...]\n","Plot summary of models saved to file: AutogluonModels/ag-20240913_104234SummaryOfModels.html\n","*** End of fit() summary ***\n"]}],"source":["results = predictor.fit_summary()"]},{"cell_type":"markdown","id":"2dcca88b","metadata":{"papermill":{"duration":0.016116,"end_time":"2024-09-13T12:42:50.475223","exception":false,"start_time":"2024-09-13T12:42:50.459107","status":"completed"},"tags":[]},"source":["* **fit_summary():** After training is complete, this method outputs a summary of the models trained, their performance, and additional statistics. The results object will contain information such as the leaderboard of model performance, training times, and which model was selected as the best for predictions."]},{"cell_type":"markdown","id":"8bd6499e","metadata":{"papermill":{"duration":0.016276,"end_time":"2024-09-13T12:42:50.508269","exception":false,"start_time":"2024-09-13T12:42:50.491993","status":"completed"},"tags":[]},"source":["# Models Leaderboard"]},{"cell_type":"code","execution_count":8,"id":"42883655","metadata":{"execution":{"iopub.execute_input":"2024-09-13T12:42:50.542394Z","iopub.status.busy":"2024-09-13T12:42:50.542041Z","iopub.status.idle":"2024-09-13T12:42:50.570828Z","shell.execute_reply":"2024-09-13T12:42:50.569817Z"},"papermill":{"duration":0.048186,"end_time":"2024-09-13T12:42:50.572975","exception":false,"start_time":"2024-09-13T12:42:50.524789","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>score_val</th>\n","      <th>eval_metric</th>\n","      <th>pred_time_val</th>\n","      <th>fit_time</th>\n","      <th>pred_time_val_marginal</th>\n","      <th>fit_time_marginal</th>\n","      <th>stack_level</th>\n","      <th>can_infer</th>\n","      <th>fit_order</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>WeightedEnsemble_L3</td>\n","      <td>-72540.884057</td>\n","      <td>root_mean_squared_error</td>\n","      <td>65.730500</td>\n","      <td>4965.730856</td>\n","      <td>0.002595</td>\n","      <td>0.507395</td>\n","      <td>3</td>\n","      <td>True</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CatBoost_BAG_L2</td>\n","      <td>-72573.800702</td>\n","      <td>root_mean_squared_error</td>\n","      <td>33.879414</td>\n","      <td>3443.217167</td>\n","      <td>0.404172</td>\n","      <td>55.281477</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>WeightedEnsemble_L2</td>\n","      <td>-72621.493206</td>\n","      <td>root_mean_squared_error</td>\n","      <td>30.205693</td>\n","      <td>3135.454129</td>\n","      <td>0.003250</td>\n","      <td>0.329934</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>LightGBMXT_BAG_L2</td>\n","      <td>-72715.627249</td>\n","      <td>root_mean_squared_error</td>\n","      <td>33.906466</td>\n","      <td>3444.350420</td>\n","      <td>0.431224</td>\n","      <td>56.414730</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>CatBoost_BAG_L1</td>\n","      <td>-72812.796073</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1.246374</td>\n","      <td>119.074448</td>\n","      <td>1.246374</td>\n","      <td>119.074448</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>NeuralNetFastAI_BAG_L2</td>\n","      <td>-72821.524851</td>\n","      <td>root_mean_squared_error</td>\n","      <td>36.878074</td>\n","      <td>3629.398750</td>\n","      <td>3.402832</td>\n","      <td>241.463060</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>LightGBMXT_BAG_L1</td>\n","      <td>-72917.481425</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.641319</td>\n","      <td>55.794910</td>\n","      <td>0.641319</td>\n","      <td>55.794910</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>LightGBM_BAG_L2</td>\n","      <td>-73067.642474</td>\n","      <td>root_mean_squared_error</td>\n","      <td>33.854123</td>\n","      <td>3442.930941</td>\n","      <td>0.378882</td>\n","      <td>54.995251</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>NeuralNetFastAI_BAG_L1</td>\n","      <td>-73204.822678</td>\n","      <td>root_mean_squared_error</td>\n","      <td>3.426627</td>\n","      <td>1470.368138</td>\n","      <td>3.426627</td>\n","      <td>1470.368138</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>LightGBM_BAG_L1</td>\n","      <td>-73211.006130</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.413517</td>\n","      <td>52.892165</td>\n","      <td>0.413517</td>\n","      <td>52.892165</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>CatBoost_r177_BAG_L1</td>\n","      <td>-73226.737654</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.405771</td>\n","      <td>45.070776</td>\n","      <td>0.405771</td>\n","      <td>45.070776</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>XGBoost_BAG_L2</td>\n","      <td>-73405.238402</td>\n","      <td>root_mean_squared_error</td>\n","      <td>34.678620</td>\n","      <td>3432.019403</td>\n","      <td>1.203378</td>\n","      <td>44.083714</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>NeuralNetTorch_BAG_L1</td>\n","      <td>-73453.134631</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1.180547</td>\n","      <td>901.138193</td>\n","      <td>1.180547</td>\n","      <td>901.138193</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>LightGBMLarge_BAG_L1</td>\n","      <td>-73620.198965</td>\n","      <td>root_mean_squared_error</td>\n","      <td>0.572073</td>\n","      <td>60.221874</td>\n","      <td>0.572073</td>\n","      <td>60.221874</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>XGBoost_BAG_L1</td>\n","      <td>-73649.378532</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1.010213</td>\n","      <td>41.470863</td>\n","      <td>1.010213</td>\n","      <td>41.470863</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>ExtraTreesMSE_BAG_L2</td>\n","      <td>-74087.679922</td>\n","      <td>root_mean_squared_error</td>\n","      <td>46.518420</td>\n","      <td>3682.227837</td>\n","      <td>13.043179</td>\n","      <td>294.292147</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>NeuralNetTorch_r79_BAG_L1</td>\n","      <td>-74226.248751</td>\n","      <td>root_mean_squared_error</td>\n","      <td>1.284742</td>\n","      <td>106.047982</td>\n","      <td>1.284742</td>\n","      <td>106.047982</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>RandomForestMSE_BAG_L2</td>\n","      <td>-74677.255202</td>\n","      <td>root_mean_squared_error</td>\n","      <td>48.446498</td>\n","      <td>4317.772048</td>\n","      <td>14.971256</td>\n","      <td>929.836358</td>\n","      <td>2</td>\n","      <td>True</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>ExtraTreesMSE_BAG_L1</td>\n","      <td>-77344.072883</td>\n","      <td>root_mean_squared_error</td>\n","      <td>11.518689</td>\n","      <td>231.008692</td>\n","      <td>11.518689</td>\n","      <td>231.008692</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>RandomForestMSE_BAG_L1</td>\n","      <td>-78153.007850</td>\n","      <td>root_mean_squared_error</td>\n","      <td>11.775370</td>\n","      <td>304.847648</td>\n","      <td>11.775370</td>\n","      <td>304.847648</td>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        model     score_val              eval_metric  \\\n","0         WeightedEnsemble_L3 -72540.884057  root_mean_squared_error   \n","1             CatBoost_BAG_L2 -72573.800702  root_mean_squared_error   \n","2         WeightedEnsemble_L2 -72621.493206  root_mean_squared_error   \n","3           LightGBMXT_BAG_L2 -72715.627249  root_mean_squared_error   \n","4             CatBoost_BAG_L1 -72812.796073  root_mean_squared_error   \n","5      NeuralNetFastAI_BAG_L2 -72821.524851  root_mean_squared_error   \n","6           LightGBMXT_BAG_L1 -72917.481425  root_mean_squared_error   \n","7             LightGBM_BAG_L2 -73067.642474  root_mean_squared_error   \n","8      NeuralNetFastAI_BAG_L1 -73204.822678  root_mean_squared_error   \n","9             LightGBM_BAG_L1 -73211.006130  root_mean_squared_error   \n","10       CatBoost_r177_BAG_L1 -73226.737654  root_mean_squared_error   \n","11             XGBoost_BAG_L2 -73405.238402  root_mean_squared_error   \n","12      NeuralNetTorch_BAG_L1 -73453.134631  root_mean_squared_error   \n","13       LightGBMLarge_BAG_L1 -73620.198965  root_mean_squared_error   \n","14             XGBoost_BAG_L1 -73649.378532  root_mean_squared_error   \n","15       ExtraTreesMSE_BAG_L2 -74087.679922  root_mean_squared_error   \n","16  NeuralNetTorch_r79_BAG_L1 -74226.248751  root_mean_squared_error   \n","17     RandomForestMSE_BAG_L2 -74677.255202  root_mean_squared_error   \n","18       ExtraTreesMSE_BAG_L1 -77344.072883  root_mean_squared_error   \n","19     RandomForestMSE_BAG_L1 -78153.007850  root_mean_squared_error   \n","\n","    pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  \\\n","0       65.730500  4965.730856                0.002595           0.507395   \n","1       33.879414  3443.217167                0.404172          55.281477   \n","2       30.205693  3135.454129                0.003250           0.329934   \n","3       33.906466  3444.350420                0.431224          56.414730   \n","4        1.246374   119.074448                1.246374         119.074448   \n","5       36.878074  3629.398750                3.402832         241.463060   \n","6        0.641319    55.794910                0.641319          55.794910   \n","7       33.854123  3442.930941                0.378882          54.995251   \n","8        3.426627  1470.368138                3.426627        1470.368138   \n","9        0.413517    52.892165                0.413517          52.892165   \n","10       0.405771    45.070776                0.405771          45.070776   \n","11      34.678620  3432.019403                1.203378          44.083714   \n","12       1.180547   901.138193                1.180547         901.138193   \n","13       0.572073    60.221874                0.572073          60.221874   \n","14       1.010213    41.470863                1.010213          41.470863   \n","15      46.518420  3682.227837               13.043179         294.292147   \n","16       1.284742   106.047982                1.284742         106.047982   \n","17      48.446498  4317.772048               14.971256         929.836358   \n","18      11.518689   231.008692               11.518689         231.008692   \n","19      11.775370   304.847648               11.775370         304.847648   \n","\n","    stack_level  can_infer  fit_order  \n","0             3       True         20  \n","1             2       True         16  \n","2             2       True         12  \n","3             2       True         13  \n","4             1       True          4  \n","5             2       True         18  \n","6             1       True          1  \n","7             2       True         14  \n","8             1       True          6  \n","9             1       True          2  \n","10            1       True         10  \n","11            2       True         19  \n","12            1       True          8  \n","13            1       True          9  \n","14            1       True          7  \n","15            2       True         17  \n","16            1       True         11  \n","17            2       True         15  \n","18            1       True          5  \n","19            1       True          3  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["predictor.leaderboard()"]},{"cell_type":"markdown","id":"aa969dfa","metadata":{"papermill":{"duration":0.017625,"end_time":"2024-09-13T12:42:50.61082","exception":false,"start_time":"2024-09-13T12:42:50.593195","status":"completed"},"tags":[]},"source":["**What the Leaderboard Shows:**\n","* **Model:** The name of the model that was trained. This can include various types of models such as Random Forest, Gradient Boosting, Neural Networks, etc.\n","* **Time Training:** The time taken to train the model.\n","* **Time Prediction:** The time taken to make predictions with the model.\n","* **Score Validation:** The score (e.g., RMSE) on the validation set, indicating how well the model performs on data it hasnt seen during training.\n","* **Fit Order:** The order in which the models were trained.\n","\n","**Interpreting the Table:**\n","* **WeightedEnsemble_L2:** This is an ensemble model that combines predictions from multiple other models (e.g., LightGBM, CatBoost). It is ranked first due to its lowest RMSE on the validation set (Score_Validation).\n","* **LightGBM_BAG_L1:** A LightGBM model that was also considered. It shows slightly worse performance than the ensemble but may have taken less time to train (Training_Time)."]},{"cell_type":"markdown","id":"890a9708","metadata":{"papermill":{"duration":0.016692,"end_time":"2024-09-13T12:42:50.644306","exception":false,"start_time":"2024-09-13T12:42:50.627614","status":"completed"},"tags":[]},"source":["# Make Predictions"]},{"cell_type":"code","execution_count":9,"id":"ae662922","metadata":{"execution":{"iopub.execute_input":"2024-09-13T12:42:50.679048Z","iopub.status.busy":"2024-09-13T12:42:50.678749Z","iopub.status.idle":"2024-09-13T12:44:34.234386Z","shell.execute_reply":"2024-09-13T12:44:34.23324Z"},"papermill":{"duration":103.575881,"end_time":"2024-09-13T12:44:34.236881","exception":false,"start_time":"2024-09-13T12:42:50.661","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n","/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(io.BytesIO(b))\n"]}],"source":["test_pred = predictor.predict(test_data)"]},{"cell_type":"markdown","id":"328a2878","metadata":{"papermill":{"duration":0.017883,"end_time":"2024-09-13T12:44:34.273586","exception":false,"start_time":"2024-09-13T12:44:34.255703","status":"completed"},"tags":[]},"source":["# Submission"]},{"cell_type":"code","execution_count":10,"id":"c16ba821","metadata":{"execution":{"iopub.execute_input":"2024-09-13T12:44:34.312724Z","iopub.status.busy":"2024-09-13T12:44:34.31115Z","iopub.status.idle":"2024-09-13T12:44:34.571624Z","shell.execute_reply":"2024-09-13T12:44:34.570633Z"},"papermill":{"duration":0.281841,"end_time":"2024-09-13T12:44:34.573881","exception":false,"start_time":"2024-09-13T12:44:34.29204","status":"completed"},"tags":[]},"outputs":[],"source":["submission['price'] = test_pred\n","submission.to_csv('submission.csv', index=False)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":9057646,"sourceId":76728,"sourceType":"competition"}],"dockerImageVersionId":30761,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"papermill":{"default_parameters":{},"duration":7399.415335,"end_time":"2024-09-13T12:44:39.812846","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-09-13T10:41:20.397511","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}